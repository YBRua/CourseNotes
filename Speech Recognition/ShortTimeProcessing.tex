\chapter{Short-Time Speech Processing}
Whoever translated the name of this course should be sent back to high school to re-learn English.
\newpage

\section{Segmentations/Frames}
An underlying assumption of speech signal processing is that the speech signal is slowly-time-varying, i.e. it changes slowly with time. Based on this assuption, we can perform short-time signal processing by splitting speech signals into isolated segmentations or frames.

\subsection{Mathematical Framework of Short-Time Processing}
Short-time analysis is represented in a general form of
\[ Q_{\hat{n}} = \sum_{m=-\infty}^{+\infty}T(x[m]w[\hat{n}-m]) = \sum_{m=-\infty}^{+\infty}T(x[m])\tilde{w}[\hat{n}-m] \]
where $\tilde{w}[\hat{n}-m]$ is a sliding analysis window and $T()$ is the operation on input signal. $Q_{\hat{n}}$ represents the short-time representation of signal $\tilde{x}$ at time $\hat{n}$.
\begin{remark}
    It's actually a discrete-time convolution of $T(x[m])$ with $\tilde{w}[n]$
\end{remark}

\subsection{Length of Segments}
The shorter the segement, the less likely a signal will vary significantly over the segment duration (due to its slowly-changing nature), and thus tracking abrupt waveform changes is best for shorter segements.
However, parameters estimated from short may be highly variable because the data available for processing is small.

\subsection{Stepsize}
Typically, the window is moved in jumps of $R>1$ samples, which corresponds to downsampling the output of the signal by a factor of $R$. If the window is of length $L$, then we should choose $R<L$ so that each sample is included in at least one segement. 

Typically, the analysis windows overlap by more than $50\%$ of the window length.

\subsection{Commonly Used Windows}
\begin{itemize}
    \item Rectangular Window
    \[ w_R[n] = 
    \begin{cases}
        1 &(0 \le n \le L-1)\\
        0 &(\text{o.w.})
    \end{cases}
    \]
    \item Hamming Window
    \[ w_H[n] = 
    \begin{cases}
        0.54-0.46\cos(2\pi n/(L-1)) &(0 \le n \le L-1)\\
        0 &(\text{o.w.})
    \end{cases}
    \]
\end{itemize}

\section{Short-Time Energy and Short-Time Magnitude}
\subsection{Energy of Signal}
\begin{definition}[Energy]
    The energy of a discrete-time signal is
    \[ E = \sum_{m=-\infty}^{+\infty}(x[n])^2 \]
\end{definition}
Useless because it does not give any time-dependent properties of a speech signal.

\subsection{Short-Time Energy}
\begin{definition}[Short-Time Energy]
    \[ E_{\hat{n}} = \sum_{m=-\infty}^{+\infty} (x[m]w[\hat{n}-m])^2 = \sum_{m=-\infty}^{+\infty} (x[m])^2\tilde{w}[\hat{n}-m]\]
\end{definition}
where $w[n]$ is the window applied to $x[n]$ before squaring, and $\tilde{w}[n]$ is the corresponding window that can be applied equivalently after squaring.

For an $L$-point window,
\[ E_{\hat{n}} = \sum_{m=\hat{n}-L+1}^{\hat{n}} (x[m]w[\hat{n}-m])^2 \]

$E_{\hat{n}}$ provides a basis for distinguishing voiced speech segments from unvoiced speech segments. Unvoiced segments have significantly smaller short-time energy compared with Voiced segments.

For high-quality speech signal (high signal-to-noise ratio), $E_{\hat{n}}$ can also be used to distinguish speech from silence.

\subsection{Short-Time Magnitude}
Short-time energy can be very sensitive to large signal levels. This can be addressed by taking square roots, or using the short-time magnitude.
\begin{definition}[Short-Time Magnitude]
    \[ M_{\hat{n}} = \sum_{m=-\infty}^{+\infty} |x[m]w[\hat{n}-m]| = \sum_{m=-\infty}^{+\infty} |x[m]|\tilde{w}[\hat{n}-m]\]
\end{definition}

\section{Short-Time Zero-Crossing Rate}
A \textbf{zero-crossing} is said to occur if successive waveform samples have different algebraic signs.
\begin{definition}[Short-Time Zero-Crossing Rate]
    \[ Z_{\hat{n}} = \frac{1}{2L_{eff}}\sum_{m=\hat{n}-L+1}^{\hat{n}} |\sgn(x[m])| - \sgn(x[m-1])| \tilde{w}[\hat{n}-m] \]
\end{definition}
Typically, the window used here is a rectangular window, so
\[ Z_{\hat{n}} = \frac{1}{2L}\sum_{m=\hat{n}-L+1}^{\hat{n}} |\sgn(x[m])| - \sgn(x[m-1])| \]

Voiced speech will have relatively low zero-crossing rate, and Unvoiced speech will have relatively high zero-crossing rate.

\section{Short-Time AutoCorrelation}
\subsection{AutoCorrelation}
\begin{definition}[AutoCorrelation]
    For determinisitc or aperiodic signals
    \[ \phi[k] = \sum_{m=-\infty}^{+\infty}x[m]x[m+k] \]
    For stationary random or periodic signals
    \[ \phi[k] = \lim_{N\to\infty}\frac{1}{2N+1}\sum_{m=-N}^{N}x[m]x[m+k] \]
\end{definition}
\begin{remark}
    AutoCorrelation highlights the period of signals because a local maximum is achieved at samples $0, \pm N, \pm 2N, \dots$, regardless of the time origin of the periodic signal.
\end{remark}
\begin{proposition}
    Properties of autocorrelation:
    \begin{itemize}
        \item For periodic signals: 
        \[ \phi[k] = \phi[k+N] \]
        \item $\phi[k]$ = $\phi[-k]$
        \item $\phi[0] \le |\phi[k]|$ for all $k$
        \item $\phi[0]$ equals to the total energy for determinisitc signals and average power of random signals.
    \end{itemize}
\end{proposition}

\subsection{Short-Time AutoCorrelation}
\begin{definition}[Short-Time AutoCorrelation]
    \[ R_{\hat{n}}[k] = \sum_{m=-\infty}^{+\infty}(x[m]w[\hat{n}-m])(x[m+k]w[\hat{n}-k-m]) \]
\end{definition}
\begin{remark}
    Short-Time AutoCorrelation preserves the properties of autocorrelation in the previous section, and $R_{\hat{n}}[0]$ is equivalent to the short-time energy.
\end{remark}

\section{Short-Time Average Magnitude Difference Function}
The computation of autocorrelation involves considerable arithmetic.

Note that for a truly periodic signal,
\[ d[k] = x[n] -x[n-k] \]
would be $0$ whenever $k=0,\pm N, \pm 2N, \dots$. So it is reasonable to expect that $d[n]$ will be small at multiples of period for short segements of voiced speech.
\begin{definition}[Short-Time AMDF]
    \[ \gamma_{\hat{n}}[k] = \sum_{m=-\infty}^{+\infty} |x[\hat{n}+m]w_1[m] - x[\hat{n}+m-k]w_2[m-k] | \]
\end{definition}
\begin{remark}
    $\gamma_{\hat{n}}[k]$ would drop sharply near multiples of period.
\end{remark}

AutoCorrelation and AMDF are used to find the \textbf{pitch} (aka \textbf{foundamental frequency}) of the speech.

\section{Short-Time Fourier Transform}
\begin{definition}[Continuous Time STFT]
    \[ X(\hat{t}, \Omega) = \int_{-\infty}^{+\infty} w(\hat{t}- t)x(t)e^{-j\Omega t}\mathrm{d}t \]
\end{definition}
\begin{definition}[Discrete Time STFT]
    \[ X_{\hat{n}}(e^{j\omega}) = \sum_{m=-\infty}^{+\infty}w[\hat{n}-m]x[m]e^{-j\omega m} \]
\end{definition}
\begin{definition}[Spectrogram]
    A spectrogram is a gray-scale image whose $x$-axis is time and $y$-axis is frequency, and its colormap indicates the log amplitude.
\end{definition}
\begin{remark}
    If the band pass filter has wide bandwidth(300-900Hz), then the spectrogram has good temporal resolution but poor frequency resolution. On the other hand, if the band pass filter has narrow bandwidth(30-90Hz), then the spectrogram has poor temporal resolution but good frequency resolution.
\end{remark}