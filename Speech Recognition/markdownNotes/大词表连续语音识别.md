# 大词表连续语音识别 LVCSR
[TOC]

**大词表**：大于10k词
**连续语音**：自然且连续

# 声学单元

## 用HMM建模什么
- 词？规模不紧凑、内部语音变化难以建模、训练集中未出现的词难以处理
- 子词？
  - 音素 Phones：最小可辨识的发音声学单元。
  - 音节 Syllables：得到好的参数估计很困难

## 音素变化与协同发音
**协同发音**：某一个音素在一个特定上下文中的具体发音，受到上下文音素的影响。
- 可以把单音子模型替换成上下文相关的多音子模型。

**边界信息**：
- 词内 Within Word
- 跨词 Cross Word

# 决策树聚类
- 状态层高斯参数的绑定
- 每个节点的数据使用单个高斯描述
- 每次分裂的增益用似然度增长定义
- 对每个节点，选择似然度增长最大的问题，若增长高于预定阈值，则继续分裂当前节点

# 解码
## 令牌传递算法 Token Passing Algorithm
`raise NotImplementedError`

# Viterbi Training and Forced Alignment
## Viterbi Training
如果能预先获得每一帧对应的HMM状态，则不需要使用Baum-Welch算法，而可以直接训练GMM参数。这被称为Viterbi Training。

但是为了获得每一帧的状态的标注，需要用一个预先训练好的声学模型对数据进行强制对齐。

## 强制对齐
是一种特殊的解码过程
- 用输入语音对应的标注文本直接构建解码图，图中仅包含标注文本对应的状态。每个状态上有指向自身以及下个状态的跳转。
- 根据语音帧和已有的声学模型，选取解码图中一条最优路径将各帧匹配到解码图上。

# N-Best and Lattices
## N-Best
每个候选是一个词序列。

## Word Lattice 词图
- 节点：对应的时间信息
- 边：词的标识以及节点之间对应某个词的声学模型或语言模型分数

## 在解码过程中生成多候选
**Word-Pair Assumption**：
1. 每个状态保留 $N$ 个token
2. 每个token都按照正常的令牌传递分别传播
3. 找到所有相同历史词token的集合
4. 
