# Duality

## Lagrange Dual Function

### The Lagrangian

Consider an optimization problem (not necessarily convex) in standard form

$$ \begin{align*}
    \min &\quad f(x) \\
    \mathrm{s.t.} &\quad g_i(x) \le 0, \quad i = 1, \dots, m \\
    &\quad h_i(x) = 0, \quad i = 1,\dots,p
\end{align*} $$

We assume the domain $\mathcal{D} = \mathbf{dom}(f) \cap \bigcap \mathbf{dom}(g_i) \cap \bigcap \mathbf{dom}(h_i)$ to be nonempty.

The basic idea of Lagrangian duality is to augment the objective function with the weighted sum of the constraints.

Define the **Lagrangian** $L: \mathbb{R}^{n} \times \mathbb{R}^{m} \times \mathbb{R}^{p} \mapsto \mathbb{R}$ with domain $\mathbf{dom} L = \mathcal{D} \times \mathbb{R}^{m} \times \mathbb{R}^{p}$,

$$ L(x, \lambda, \nu) = f(x) + \sum_{i=1}^m \lambda_i g_i(x) + \sum_{i=1}^p \nu_i h_i(x) $$

$\lambda_i$ and $\nu_i$ are referred to as the **Lagrangian multipliers** associated with the $i$-th inequality/equality constraints. The vectors $\lambda, \nu$ are referred to as the **dual variables** or **Lagrangian multiplier vectors**.

### The Lagrange Dual Function

Define the **Lagrange dual function** (or **dual function**) $g: \mathbb{R}^{m} \times \mathbb{R}^{p} \mapsto \mathbb{R}$ as the minimum value of Lagrangian over $x$,

$$ g(\lambda, \nu) = \inf_{x \in \mathcal{D}} L(x, \lambda, \nu) = \inf_{x \in \mathcal{D}} \left( f(x) + \sum_{i=1}^m \lambda_i g_i(x) + \sum_{i=1}^p \nu_ih_i(x) \right) $$

- **Concavity of the Lagrange Dual Function.** The dual function is the pointwise infimum (preserves concavity) of a family of affine functions of $(\lambda, \nu)$, and hence is concave in $\lambda$ and $\nu$ (even if the original $f$ is not convex).

### Lower Bounds on Optimal Value

**Proposition.** The dual function $g$ yields a lower bound on the optimal value $p^*$. For any $\lambda \succeq 0$ and any $\nu$,

$$ g(\lambda, \nu) \le p^*. $$

!!!quote Proof
    Suppose $\tilde{x}$ is a feasible point and $\lambda \succeq 0$,

    $$ g(\lambda, \nu) \le L(\tilde{x}, \lambda, \nu) = f(\tilde{x}) + \sum_{i=1}^m \lambda_i g_i(\tilde{x}) + \sum_{i=0}^p \nu_i h_i(\tilde{x}) \le f(\tilde{x}) $$

    Note that $\lambda_i \ge 0$ and $f_i(\tilde{x}) \le 0, h_i(\tilde{x}) = 0$ by the feasibility of $\tilde{x}$.

Therefore, the function gives a nontrivial lower bound when $\lambda \succeq 0$ and $(\lambda, \nu) \in \mathbf{dom}(g)$. Such pairs of $(\lambda, \nu)$ are referred to as **dual feasible**.

### Examples

#### Least-squares Solution of Linear Equations

$$\begin{align*}
    \min &\quad x^Tx \\
    \mathrm{s.t.} &\quad Ax = b
\end{align*}
$$

The Lagrangian is

$$ L(x, \nu) = x^Tx + \nu^T (Ax - b) $$

To derive the dual function $g(\nu) = \inf_x L$, since $L$ is a convex quadratic function w.r.t. $x$, we can take the gradient and set it to zero.

$$ \nabla_x L = 2x + A^T\nu \coloneqq 0 $$

Therefore $x = -(1/2)A^T\nu$. Plug this minimizing $x$ back into $L$

$$ g(\nu) = -\frac{1}{4} \nu^T AA^T \nu - \nu^T b $$

Note that $g$ is a concave quadratic in $\nu$.

#### Standard Form LP

Consider an LP in standard form

$$\begin{align*}
    \min &\quad c^Tx \\
    \mathrm{s.t.} &\quad Ax = b\\
    &\quad x \succeq 0
\end{align*}$$

The Lagrangian is

$$ L(x, \lambda, \nu) = c^Tx - \lambda^T x + \nu^T(Ax - b). $$

Note that in the equation we have $-\lambda^T$ because the inequality in standard LP is "$\ge$" but the Lagrangian requires "$\le$".

$$ L(x, \lambda, \nu) = -b^T\nu + (c + A^T\nu -\lambda)^T x. $$

$$g(\lambda, \nu) = \inf_x L = \begin{cases}
    -b^T\nu &\quad c + A^T \nu - \lambda = 0 \\
    -\infty &\quad \text{otherwise}
\end{cases}$$

The lower bound property is nontrivial only when $\lambda \succeq 0$ and $A^T\nu - \lambda + c = 0$. We can reformulate this by explicitly including the dual feasibility as constraints

$$\begin{align*}
    \max &\quad -b^T\nu \\
    \mathrm{s.t.} &\quad A^T\nu - \lambda = -c\\
    &\quad \lambda \ge 0
\end{align*}$$

which is also an LP in standard form.

Further, we can remove $\lambda$ and express the problem as

$$\begin{align*}
    \max &\quad -b^T\nu \\
    \mathrm{s.t.} &\quad A^T\nu + c \succeq 0\\
\end{align*}$$

The dual of a standard LP is an LP with only inequality constraints. Actually it can be shown the converse also holds: the dual of an inequality form LP is a standard form LP.

#### Two-way Partition

Consider a nonconvex problem

$$ \begin{align*}
    \min &\quad x^TWx \\
    \mathrm{s.t.} &\quad x_i^2 = 1
\end{align*} $$

where $W \in \mathbb{R}^{n \times n}$ is symmatric.

Note that the feasible set is $\{1, -1\}^n$, which is discrete and nonconvex. Still, we can write the Lagrangian,

$$ L(x, \nu) = x^TWx + \sum_{i=1}^n \nu_i^T (x_i^2 - 1) $$

$$ g(\nu) = \inf_x L(x, \nu) = \inf_x \left( x^TWx + \sum_{i=1}^n \nu_i (x_i^2 - 1) \right) $$

We can rewrite $\sum_i \nu_i x_i^2$ as $x^T \mathrm{diag}(\nu)x $,

$$ g(\nu) = \inf_x \left( x^T\left( W + \mathrm{diag}(\nu) \right) x - \sum_{i}\nu_i \right) $$

$$ g(\nu) = \begin{cases}
    -\mathbf{1}^T \nu &\quad W + \mathrm{diag}(\nu) \ge 0\\
    -\infty &\quad \text{otherwise}
\end{cases} $$

The dual function provides a lower bound on the optimal value of the original nonconvex problem. For example, take

$$ \nu = -\lambda_{min}(W)\mathbf{1} $$

which is dual feasible, since

$$ W + \mathbf{diag}(\nu) = W - \lambda_{min}(W)I \ge 0 $$

which yields a lower bound

$$ p^* \ge -\mathbf{1}^T\nu = n\lambda_{min}(W) $$

### Langrangian Dual Function and Conjugate Functions

!!!info Recap. Conjugate Function
    The conjugate function $f^*$ of a function $f$ is given by

    $$ f^*(y) = \sup_{x \in \mathbf{dom}(f)} (y^Tx - f(x)) $$

Consider

$$ \begin{align*}
    \min &\quad f(x) \\
    \mathrm{s.t.} &\quad Ax \le b\\
    &\quad Cx = d
\end{align*} $$

Dual function

$$\begin{align*}
    g(\lambda, \nu) &= \inf_x (f(x) + \lambda^T(Ax -b) + \nu^T (Cx - d))\\
    &= \inf_x \left( f(x) + (A^T\lambda + C^T\nu)^Tx \right) - b^T\lambda - d^T\nu\\
    &= \inf_x \left( -y^Tx + f(x) \right) - b^T\lambda -d^T \nu \qquad (\text{letting } y = -(A^T\lambda + C^T\nu)) \\
    &= -\sup_x \left( y^Tx - f(x) \right) - b^T\lambda -d^T \nu\\
    &= -f^*(-(A^T\lambda + C^T\nu)) - b^T\lambda - d^T\nu
\end{align*}$$

#### Equality Constrained Norm Minimization

$$\begin{align*}
    \min &\quad \|x\| \\
    \mathrm{s.t.} &\quad Ax = b
\end{align*}$$

where $\|\cdot\|$ can be any norm. Recall that the conjugate of $f(x) = \|x\|$ is given by

$$f^*(y) = \begin{cases}
    0 &\quad \|x\|_* \le 1 \\
    \infty &\quad o.w.
\end{cases}$$

Therefore the dual function for this problem is given by

$$ g(\nu) = -f^*(-A^T\nu) - b^T\nu = \begin{cases}
    -b^T\nu &\quad \|A^T\nu\|_* \le 1\\
    -\infty &\quad o.w.
\end{cases} $$

#### Entropy Maximization

$$\begin{align*}
    \min &\quad f_0(x) = \sum_{i=1}^n x_i \log x_i \\
    \mathrm{s.t.} &\quad Ax \preceq b\\
    &\quad \mathbf{1}^T x = 1
\end{align*}$$

The conjugate of $f(x) = x \log x$ is $f^*(y) = e^{y-1}$, and therefore

$$ f^*_0(y) = \sum_{i=1}^n e^{y_i - 1} $$

Plug everything in

$$ g(\lambda, \nu) = -b^T\lambda -\nu -e^{-\nu-1}\sum_{i=1}^n e^{-a_i^T\lambda} $$

## Lagrange Dual Problem

The Lagrange dual function gives a lower bound on the optimal value $p^*$ of the original optimization problem. We then consider what is the *best* lower bound that can be obtained.

$$ \begin{align*}
    \max &\quad g(\lambda, \nu) \\
    \mathrm{s.t.} &\quad \nu \ge 0
\end{align*} $$

This is called the **Lagrangian dual problem** associated with the original optimization problem (sometimes called the **primal problem**).

The dual problem is a *convex* problem, because it is a maximization of concave problem, under convex constraints. This is the case regardless of whether or not the primal problem is convex.

### Weak Duality

**Weak Duality.** Denote the optimal value of the Lagrange dual problem by $d^*$. It is the best lower bound of $p^*$.

$$ d^* \le p^* $$

The weak duality *always holds*.

The difference $p^* - d^*$ is referred to as the **optimal duality gap** of the original problem.

### Strong Duality and Slater's Constraint Qualification

**Strong Duality.** We say the strong duality holds if

$$ d^* = p^* $$
- Does not hold in general.
- Typically holds for convex problems under various conditions, known as **constraint qualifications**.
- Might also hold for non-convex problems.
- When strong duality holds, we can solve the dual problem for the optimal value instead, if it is easier to solve.

#### Slater's Condition

Consider a standard convex optimization problem

$$\begin{align*}
    \min &\quad f(x) \\
    \mathrm{s.t.} &\quad g_i(x) \le 0\\
    &\quad Ax = b
\end{align*}$$

**Slater's Condition.** The problem is **strictly feasible**, i.e., $\exists x \in \mathbf{relint}(\mathcal{D})$ such that the inequality constraints strictly hold.

$$ g_i(x) < 0, i = 1,2,\dots,m $$

**Refined Slater's Condition.** If some constraints $g_j$ are affine, the requirement $g_j(x) < 0$ can be relaxed to equality $g_j(x) \le 0$.

- The Refined Slater's Condition reduces to feasiblity if all inequality (and equality) constraints are affine and $\mathbf{dom}(f)$ is open.

**Slater's Theorem.** Strong duality holds for the convex optimization theorem under (refined) Slater's Condition. Furthermore, if the problem is dual feasible ($d^* > -\infty$), it is attained by some $(\lambda^*, \nu^*)$.

- For convex problems, Slater's condition not only implies strong duality, it also implies that the dual optimal value is attained if the problem is dual feasible.

!!!note ""
    Note that the Slater's condition is only a sufficient condition for strong duality. It is not necessary.

## Optimality Conditions

### Complementary Slackness

Assume strong duality holds, and $x^*$ is primal optimal, $(\lambda^*, \nu^*)$ are dual optimal.

This implies

$$\begin{align*}
    f(x^*) &= g(\lambda^*, \nu^*) \\
    &= \inf_{x \in D} \left( f(x) + \sum_{i=1}^m \lambda_i^* g_i(x) + \sum_{i=1}^p \nu_i^* h_i(x) \right)\\
    &\le f(x^*) + \sum_{i=1}^m \lambda_i^* g_i(x^*) + \sum_{i=1}^p \nu_i^* h_i(x^*)\\
    &\le f(x^*)
\end{align*} \tag{1}$$

- $h_i(x^*) = 0$ (primal equality constraint) and that $\lambda_i^* g_i(x^*) \le 0$ since $\lambda_i^* \ge 0$ and $g_i(x^*) \le 0$ (primal inequality constraint).
- LHS is equal to RHS. The two inequalities in this chain should hold with equality.

**Complementary Slackness.** An important conclusion is that

$$ \sum_{i=1}^m \lambda_i^* g_i(x^*) = 0$$

Since each component in the above summation is nonpositive, it follows that

$$ \lambda_i^* g_i(x^*) = 0, i = 1,\dots,m  $$

This is known as the **complementary slackness** condition. It holds for any primal and dual optimal when strong duality holds.

Complementary slackness can be expressed as

$$ \lambda_i^* > 0 \Longrightarrow f_i(x^*) = 0 \quad \text{or} \quad f_i(x^*) < 0 \Longrightarrow \lambda_i^* = 0 $$

This means the $i$-th optimal Lagrange multiplier is zero unless the $i$-th inequality constraint is *active* at the optimum.

### Karush-Kuhn-Tucker (KKT) Conditions

The **KKT Conditions** consists of the following constraints

1. **Primal Constraints.** $g_i(x) \le 0$ and $h_i(x) = 0$.
2. **Dual Constraints.** $\lambda_i \ge 0$, where $\lambda_i$ are the multipliers for the inequality constraints.
3. **Complementary Slackness.** $\forall i , \lambda_i g_i(x) = 0$.
4. **Stationarity.** $\nabla_x \mathcal{L}(x,\lambda,\nu) = 0$. This is because $x$ minimizes $\mathcal{L}$, which follows from (1).

**KKT Optimality Conditions.** For *any* optimization problem with differentiable objective and constraints, for which *strong duality holds*, any pair of primal and dual optimal points must satisfy the KKT conditions.

**KKT Optimality Conditions for Convex Problems.** If the primal problem is convex, and strong duality holds, the KKT Conditions are sufficient and necessary for optimality. I.e., KKT conditions hold at $x^*$ with multipliers $\lambda^*, \nu^*$ if and only if (1) strong duality holds, and (2) $x^*, (\lambda^*, \nu^*)$ are primal and dual optimals.

## Perturbation and Sensitivity Analysis

Consider a perturbed version of the original optimization problem

$$\begin{align*}
    \min &\quad f(x) \\
    \mathrm{s.t.} &\quad g_i(x) \le u_i, i = 1,\dots,m\\
    &\quad h_i(x) = v_i, i = 1,\dots,p
\end{align*}$$

This problem coincides with the original optimization problem if $u_i = 0$ and $v_i = 0$.

Due to the perturbations, the dual problem would be

$$\begin{align*}
    \max &\quad g(\lambda, \nu) - u^T\lambda - v^T\nu\\
    \mathrm{s.t.} &\quad \lambda \ge 0
\end{align*}$$

Further define $p^*(u, v)$ to be the optimal value of $f$ as a function of $u, v$.

### A Global Inequality (Global Analysis)

Assume strong duality holds, and the dual optimum is attained, let $\lambda^*, \nu^*$ be the dual optimal for the original (unperturbed) problem.

$$ p^*(u, v) \ge g(\lambda^*, \nu^*) - u^T \lambda^* - v^T\nu^* $$

- **Sensitivity Interpretations.**
  - If $\lambda^*$ is large, and $u_i < 0$, $p^*$ is guaranteed to increase greatly.
  - If $\lambda^*$ is small, and $u_i > 0$, $p^*$ will not decrease greatly.
  - If $\nu^*$ is large,
    - If $\nu^* > 0$, and $v_i < 0$, $p^*$ is guaranteed to increase greatly.
    - If $\nu^* < 0$, and $v_i > 0$, $p^*$ is guaranteed to increase greatly.
  - If $\nu^*$ is small,
    - If $\nu^* > 0$ and $v_i > 0$, 
    - Or if $\nu^* < 0$ and $v_i < 0$, then $p^*$ will not decrease greatly.

### Local Sensitivity Analysis

Assume $p^*(u,v)$ is differentiable at $u=0, v=0$.

Provided the strong duality holds, then

$$ \lambda_i^* = -\frac{\partial p^*(0,0)}{\partial u_i}, \quad \nu_i^* = -\frac{\partial p^*(0,0)}{\partial v_i} $$

Thus the optimal Lagrange multipliers are the local sensitivities of the optimal value, w.r.t. constraint perturbations.

## Examples

### Examples for KKT Optimality Conditions

#### Water-Filling “灌水问题”

$$ \begin{align*}
    \min &\quad -\sum_{i=1}^n \log(x_i + \alpha_i) \\
    \mathrm{s.t.} &\quad x \ge 0, 1^Tx = 1
\end{align*} $$

where $\alpha_i \ge 0$.

Introduce multipliers $\lambda_i, \nu_i$. The Lagrangian is

$$ \mathcal{L}(x, \lambda, \nu)  -\sum_{i=1}^n\log(x_i + \alpha_i) - \sum_i \lambda_i x_i + \nu (1^Tx - 1) $$


The KKT conditions,

- $x \ge 0$, $1^Tx = 1$
- $\lambda_i \ge 0$
- $\lambda_i x_i = 0$
- $ -\frac{1}{x_i + \alpha_i} - \lambda_i + \nu = 0 $

By the complementary slackness condition,

- if $\lambda_i = 0$, $x_i = \frac{1}{\nu} - \alpha_i \ge 0$, $\nu \le \frac{1}{\alpha_i}$.
- if $x_i = 0$, similarly we have $\nu > \frac{1}{\alpha_i}$

Therefore $x_i = \max\{ 0, 1/\nu^* - \alpha_i \}$. Substituting this for $1^Tx = 1$, we have

$$ \sum_{i=1}^n \max\{ 0, 1/\nu^* - \alpha_i \} = 1$$

This problem is referred to as the **water-filling** problem because it can be interpreted as flooding a region (containing patches of height $\alpha_i$) with water of depth $1/\nu$, with the total amount of used water equal to one. The level of water above each patch $\alpha_i$ is the value for $x_i^*$.

### Introducing New Variables and Constraints

Consider an unconstrained problem

$$ \min \quad f(Ax + b) $$

The dual function is a constant, $p^*$, so we have strong duality, but it is neither useful nor interesting.

We can reformulate the problem as

$$\begin{align*}
    \min &\quad f(y) \\
    \mathrm{s.t.} &\quad Ax + b = y
\end{align*}$$

The Lagrangian is

$$ L(x,y,\nu) = f(y) + \nu^T(Ax+ b-y) $$

Note that $L$ is unbounded below w.r.t. $x$ unless $A^T\nu = 0$, in which case we have

$$ g(\nu) = b^T\nu + \inf_y (f(y) - \nu^Ty) = b^T\nu - f^*(\nu) $$

And the dual problem would be

$$ \begin{align*}
    \max &\quad b^T \nu - f^*(\nu) \\
    \mathrm{s.t.} &\quad A^T\nu = 0
\end{align*} $$

where $f^*$ is the conjugate of $f$.

#### Norm Approximation

$$ \min \|Ax - b\| $$

Reformulate the problem as

$$\begin{align*}
    \min &\quad \|y\| \\
    \mathrm{s.t.} &\quad Ax - b = y
\end{align*}$$

Using the fact that the conjugate of a norm is the indicator of the unit ball of dual norm, the dual problem is thus

$$\begin{align*}
    \max &\quad b^T\nu \\
    \mathrm{s.t.} &\quad \|\nu\|_* \le 1\\
    &\quad A^T \nu = 0
\end{align*}$$

### Implicit Constraints

We can include some of the constraints directly in the objective function, by modifying the objective to be infinite when constraints are violated.

#### Linear Programming with Box Constraints

$$\begin{align*}
    \min &\quad c^Tx \\
    \mathrm{s.t.} &\quad Ax = b\\
    &\quad -1 \le x \le 1
\end{align*}$$

The Lagrangian is

$$ \mathcal{L}(x, \lambda_1, \lambda_2, \nu) = c^Tx + \lambda_1^T(x-1) + \lambda_2^T (-1-x) + \nu^T(Ax - b) $$

The dual problem is

$$ \begin{align*}
    \max &\quad -b^T\nu - \lambda_1^T 1 - \lambda_2^T 1 \\
    \mathrm{s.t.} &\quad c + \lambda_1 - \lambda_2 + A^T\nu = 0
\end{align*} $$

We can reformulate the problem as

$$\begin{align*}
    \min &\quad \begin{cases}
        c^Tx &\quad -1 \le x \le 1\\
        +\infty &\quad o.w.
    \end{cases} \\
    \mathrm{s.t.} &\quad Ax = b\\
\end{align*}$$

The dual function is then

$$ g(\nu) = \inf_{-1 \le x \le 1} (c^Tx + \nu^T(Ax - b)) = \inf_{-1 \le x \le 1} ((c + A^T\nu)^Tx) - b^T\nu $$

Note that for $(c + A^T\nu)^Tx$ to reach its minimal value, we simply let $x_i$ to have different sign with the $i$-th element of $c + A^T\nu$. Therefore,

$$ g(\nu) = -\| c + A^T\nu \|_1 - b^T\nu $$

The dual problem is therefore

$$ \max_\nu -\| c+ A^T\nu \|_1 - b^T\nu $$
