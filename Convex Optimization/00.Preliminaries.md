# Preliminaries

## Norms

### Inner Product, Euclidean Norm, Angle

### Vectors

**Inner Product.** The **standard inner product** on $\mathbb{R}^n$ is given by

$$ \langle x, y \rangle = x^T y = \sum_{i=1}^n x_i y_i $$

**Euclidean Norm.** The **Euclidean norm**, or $L_2$-norm, of a vector $x \in \mathbb{R}^n$ is defined as

$$ \| x \|_2 = (x^Tx)^{1/2} = (x_1^2 + \cdots + x_n^2)^{1/2} $$

**The Cauchy-Schwartz Inequality.** The **Cauchy-Schwartz inequality** states that $\forall x, y \in \mathbb{R}^n$

$$ | x^Ty | \le \|x\|_2\|y\|_2 $$

**Angle.** The **(unsigned) angle** between nonzero vectors $x, y \in \mathbb{R}^n$ is defined as

$$ \angle(x, y) = \cos^{-1}\frac{x^Ty}{\|x\|_2\|y\|_2} $$

We say $x$ and $y$ are **orthogonal** if $x^Ty = 0$.

### Matrices

**Inner Product of Matrices.** The **standard inner product** on $\mathbb{R}^{m \times n}$ is given by

$$ \langle X, Y \rangle = \mathrm{tr}(X^TY) = \sum_{i=1}^m \sum_{j=1}^n X_{ij}Y_{ij} $$

If $X, Y$ are symmetric $n \times n$ matrices, then the inner product can be written as

$$ \mathrm{tr}(X^TY) = \sum_{i=1}^m \sum_{j=1}^n X_{ij}Y_{ij} = \sum_{i=1}^n X_{ii}Y_{ii} + 2 \sum_{i < j} X_{ij}Y_{ij} $$

**Frobenius Norm.** The **Frobenius norm** of a matrix $X \in \mathbb{R}^{m \times n}$ is

$$ \| X \|_F = \left( \mathrm{tr}(X^TX) \right)^{1/2} = \left( \sum_{i=1}^m \sum_{j=1}^n X_{ij}^2 \right)^{1/2} $$

The Forbenius norm is the Euclidean norm of the vector obtained by "flattening" $X$.

### Norms, Distance, Unit Ball

**Norm.** A function $f: \mathbb{R}^n \mapsto \mathbb{R}$ with $\mathrm{dom}(f) = \mathbb{R}^n$ is called a **norm** if

- $f$ is nonnegative: $f(x) \ge 0$ for all $x \in \mathbb{R}^n$.
- $f$ is definite: $f(x) = 0$ only if $x = 0$.
- $f$ is homogeneous: $f(tx) = |t|f(x)$.
- $f$ satisfies the *triangle inequality*: $f(x + y) \le f(x) + f(y)$.

The norm of $x$ is denoted by $\| x \|$.

**Distance.** A norm is a measure of the *length* of a vector $x$. We can measure the **distance** between $x$ and $y$ as the lengths of their difference.

$$ \mathrm{dist}(x, y) = \| x - y \| $$

**Norm balls.** The set of all vectors with norm less than or equal to one is called the **unit ball** of norm $\| \cdot \|$.

$$ \mathcal{B} = \{ x \in \mathbb{R}^n | \| x \| \le 1 \} $$

The norm ball satisfies the following properties

- $\mathcal{B}$ is symmetric about the origin.
- $\mathcal{B}$ is convex.
- $\mathcal{B}$ is closed, bounded and has nonempty interior.

#### Examples

- **Euclidean Norm ($L_2$-Norm).**
- **$L_1$-Norm.** $\|x\|_1 = |x_1| + \cdots + |x_n|$.
- **Chebyshev Norm ($L_{\infty}$-Norm).** $\| x\|_{\infty} = \max\{ |x_1|,\dots,|x_n| \}$.
- **$L_p$-Norm.** $\|x\|_p = (|x_1|^p + \cdots + |x_n|^p)^{1/p}$.

##### Quadratic Norms

For $P \in \mathbb{S}_{++}^n$, we define the **$P$-quadratic norm** as

$$ \| x \|_P = (x^TPx)^{1/2} = \| P^{1/2}x \|_2 $$

The unit ball of a quadratic norm is an ellipsoid, and conversely, if the unit ball of a norm is an ellipsoid, it is the unit ball of a quadratic norm.

##### Frobenius Norm

See [matrix norms](#matrices) above.

$$ \| X \|_F = \left( \mathrm{tr}(X^TX) \right)^{1/2} = \left( \sum_{i=1}^m \sum_{j=1}^n X_{ij}^2 \right)^{1/2} $$

#### Equivalence of Norms

Any norms on any *finite-dimensional* vector space are equivalent.

### Operator Norm

Suppose $\|\cdot\|_a$ and $\|\cdot\|_b$ are two norms on $\mathbb{R}^m$ and $\mathbb{R}^n$ respectively. The **operator norm** of $X \in \mathbb{R}^{m \times n}$ induced by the norms$\|\cdot\|_a$ and $\|\cdot\|_b$ is defined as

$$ \| X \|_{a, b} = \sup\{ \|Xu\|_a \mid \|u\|_b \le 1 \} $$

- When both $\|\cdot\|_a$ and $\|\cdot\|_b$ are Euclidean norms, the operator norm of $X$ is the *maximum singular value* norm, denoted $\|X\|_2$. $ \|X\|_2 = \sigma_{max}(X) = (\lambda_{max}(X^TX))^{1/2} $. This is also known as the **spectral norm** or **$L_2$-Norm** of $X$.
- The norm induced by the $L_{\infty}$-norm, denoted $\|X\|_{\infty}$, is the *max-row-sum* norm. $\|X\|_{\infty} = \sup\{ \|Xu\|_{\infty} \mid \|u\|_{\infty} \le 1 \} = \max_{i} \sum_{j=1}^n |X_{ij}|$.
- The norm induced by the $L_1$-norm, denoted $\|X\|_1$., is the *max-column-sum* norm. $\|X\|_1 = \max_j \sum_{i=1}^m |X_{ij}|$.

### Dual Norm

Let $\| \cdot \|$ be a norm on $\mathbb{R}^n$. The associated **dual norm**, denoted $\| \cdot \|_*$ is defined as

$$ \|z\|_* = \sup\{ z^Tx \mid \|x\| \le 1 \} $$

#### Examples

##### Euclidean Norm

The dual of the Euclidean norm is the Euclidean norm itself,

$$ \|z\|_* = \sup_{\|v\|_2 \le 1} z^Tv = \|z\|_2\cdot\|v\|_2\cos\theta = \|z\|_2 $$

##### $L_1$-Norm

$$ \|z\|_* = \sup\{ z^Tv \mid \|v\|_1 \le 1 \} $$

$$ z^Tv = \sum_i z_iv_i \le \sum_i z_i |v_i| \le \sum_i |z_i| |v_i| \le \sup_i|z_i| \sum_i |v_i| \le \sup_i |z_i| = \|z\|_{\infty} $$

##### $L_p$-Norm

It can be shown that

$$ \| z \|_{p*} = \|z\|_q $$

where $1/p + 1/q = 1$.

##### Quadratic Norm

The **$P$-quadratic norm** is defined as

$$ \|x\|_P = \left( x^TPx \right)^{1/2} = \| P^{1/2}x \| $$

where $P \in \mathbb{S}_{++}^n$.

Since $P \in \mathbb{S}_{++}^n$, it can be decomposed as

$$ P = V \Sigma V^T = \sum_i \lambda_i v_iv_i^T $$

Now consider the dual norm

$$ \|z\|_{P*} = \sup\{ z^Tu | \|u\|_P \le 1 \} $$

Note that $v_1,\dots,v_n$ are a set of orthonormal vectors. Therefore we can rewrite $z$ as

$$ z = \sum_i a_i v_i \quad u = \sum_i b_i v_i $$

Therefore

$$ \|u\|_P = (U^TPU)^{1/2} = \left( \sum_{i=1}^n b_iv_i^T \sum_{j=1}^n \lambda_j v_j v_j^T \sum_{k=1}^n b_k v_k \right)^{1/2} $$

Since $v_i$'s are orthonormal, $v_i v_j = 0$ if $i \neq j$.

$$ \|u\|_P = \left( \sum_{i=1}^n b_i v_i^T \lambda_i v_i v_i^T b_i v_i \right)^{1/2} = \left( \sum_{1}^n b_i^2 \lambda_i \right)^{1/2} \le 1 $$

Therefore

$$ \sum_{i=1}^n b_i^2 \lambda_i \le 1 $$

And

$$ z^Tv = \sum_i a_i v_i^T \sum_j b_j v_j = \sum_i a_i b_i = \sum_i \frac{a_i}{\sqrt{\lambda_i}} \cdot b_i\sqrt{\lambda_i} $$

Note that by Cauchy-Schwarz inequality

$$ \begin{align*}
    z^Tv &\le \left( \sum_i \left( \frac{a_i}{\sqrt{\lambda_i}} \right)^2 \sum_i \left( b_i\sqrt{\lambda_i} \right)^2 \right)^{1/2}\\
    &= \left( \sum_i \frac{a_i^2}{\lambda_i} \sum_i b_i^2 \lambda_i \right)^{1/2}\\
    &\le \left( \sum_i \frac{a_i^2}{\lambda_i} \right)^{1/2}
\end{align*} $$

TBD.

$$ \|z\|_{P*} = \|z\|_{P^{-1}} $$

## Analysis

### Open and Closed Sets

**Interior.** An element $x \in C$ is an **interior point** of $C$ if there exists an $\epsilon > 0$ for which

$$ \{ y \mid \| y-x \|_2 \le \epsilon \} \subseteq C $$

i.e., there exists a ball centered at $x$ that lies entirely in $C$.

The set of all points interior to $C$ is called the **interior** of $C$, denoted $\mathrm{int}(C)$.

**Open and Closed Sets.** A set is **open** if $\mathrm{int}(C) = C$, i.e., every point in $C$ is an interior point. A set is **closed** if its complement $\mathbb{R}^n \backslash C$ is open.

**Closure.** The **closure** of a set $C$ is defined as

$$ \mathrm{cl}(C) = \mathbb{R}^n \backslash \mathrm{int}(\mathbb{R}^n \backslash C) $$

i.e., the complement of the interior of the complement of $C$.

A point $x$ is in the closure of $C$ if for every $\epsilon > 0$, there is a $y \in C$ with $\| x-y \|_2 \le \epsilon$.

**Boundary.** The boundary of a set is defined as

$$ \mathrm{bd}(C) = \mathrm{cl}(C) \backslash \mathrm{int}(C) $$

A **boundary point** $x \in \mathrm{bd}(C)$ satisfies: for all $\epsilon > 0$, there exists $y \in C$ and $z \notin C$ with

$$ \| y - x \|_2 \le \epsilon, \quad \| z - x \|_2 \le \epsilon $$

- A set is closed if it contains its boundary ($\mathrm{bd}(C) \subseteq C$)
- A set is open if it does not contain any point in its boundary $(\mathrm{bd}(C) \cap C = \emptyset)$

### Supremum and Infimum

**Upper bound.** A number $a$ is an **upper bound** on a set $C$ if for each $x \in C$, $x \le a$.

The set of upper bounds is either empty, or the entire $\mathbb{R}$, or a closed infinite interval $[b, \infty)$.

- The set $C$ is *unbounded above* if the set of upper bound is empty.

**Supremum.** If the set of upper bounds is a closed infinite interval, $b$ is called the **least upper bound**, or the **supremum**, denoted $sup(C)$.

- $\mathrm{sup}(\emptyset) = -\infty$.
- $\mathrm{sup}(C) = \infty$ if $C$ is unbounded above.

**Lower bound.** A number $a$ is a **lower bound** on a set $C$ if for each $x \in C$, $a \le x$.

**Infimum.** The **infimum** of a set $C$ is defined as $\inf(C) = -\sup(-C)$.

### Functions


