# Unconstrained Minimization

## Unconstrained Minimization Problems

$$ \min f(x) $$

where $f: \mathbb{R}^n \mapsto \mathbb{R}$ is convex and twice continuously differentiable. We further assume that the problem is solvable.

Since $f$ is differentiable and convex, a necessary and sufficient condition for $x^*$ to be a minimizer is that

$$ \nabla_x f(x^*) = 0 $$

### Examples

#### Quadratic Minimization

$$ \min \frac{1}{2}x^TPx + q^Tx + r $$

where $P \in \mathbb{S}_{+}^n$, $q \in \mathbb{R}$, $r \in \mathbb{R}$.

$$ \nabla_x f(x) = Px + q $$

- If $P \in \mathbb{S}_{++}^n $, then $\nabla_x f(x) = 0$ has a unique solution $x = -P^{-1}q$.

#### Geometric Programming

$$ \min f(x) = \log\left( \sum_{i=1}^m \exp\left( a^T_i x + b_i \right) \right) $$

$$ \nabla f(x) = \frac{\sum_{i=1}^m a_i \exp\left( a^T_i x + b_i \right)}{\sum_{i=1}^m \exp\left( a^T_i x + b_i \right)} $$

## Strong Convexity

A function is **strongly convex** if there exists an $m > 0$ such that

$$ \nabla^2 f(x) \ge mI $$

- **Remarks.** Strong convexity means
  - $(\nabla^2 f(x) - mI) \in \mathbb{S}_{++}^n$
  - The minimum eigenvalue of $\nabla^2 f(x)$ is at least $m$.

### Implications of Strong Convexity

#### A Better Lower Bound

For $x, y \in S$, we have

$$ f(y) = f(x) + \nabla f(x)^T (y-x) + \frac{1}{2}(y-x)^T\nabla^2f(z)(y-x) $$

which is the second-order Taylor expansion. By the strongly convex assumption, the last term is at least $\frac{1}{2}\|y-x\|^2$, and therefore

$$ f(y) \ge f(x) + \nabla f(x)^T (y-x) + \frac{m}{2}\|y-x\|^2 $$

This establishes a relationship between the input ($y-x$) and output ($f(y) - f(x)$). It gives a better lower bound for $f(y)$.

#### Bounding the Suboptimal Points

We start from the lower bound for $f(y)$

$$ f(y) \ge f(x) + \nabla f(x)^T (y-x) + \frac{m}{2}\|y-x\|^2 $$

The RHS is a convex function w.r.t. $y$, and hence the minimum is achieved at the stationary point

$$ \tilde{y} = x - (1/m)\nabla f(x) $$

Plug this back to the inequality, $f(y) \ge f(x) - \frac{1}{2m}\|\nabla f(x)\|^2$, and therefore

$$ f(x) - f(y) \le \frac{1}{2m}\|\nabla f(x)\|^2 $$

Since $y \in S$ is arbitrary, let $y$ be the minimizer,

$$ f(x) - p^* \le \frac{1}{2m}\|\nabla f(x)\|^2 $$

We thus essentially bound the suboptimality of $x$ by its gradient.

### Condition Number

Let $\nabla^2f(x) \in \mathbb{S}_{++}^n$ with eigenvalues $ \lambda_1 \le \cdots \le \lambda_n$.

The **condition number** is defined as

$$ \kappa(\nabla^2 f(x)) = \frac{\lambda_n}{\lambda_1} $$

## Descent Methods

### General Descent Methods

The descent methods produce a sequence of minimizing sequence $x^{(k)}$, where

$$ x^{(k+1)} = x^{(k)} + t^{(k)} \Delta x^{(k)} $$

where $t^{(k)}$ is the step size and $\Delta x^{(k)}$ is a search direction.

A **descent method** satisfies

$$ f\left( x^{(k+1)} \right)  \le f\left( x^{(k)} \right)$$

except when $x$ is optimal.

From convexity we know that $\nabla f(x^{(k)})^T( y - x^{(k)} ) \ge 0$ implies $f(y) \ge f(x^{(k)})$, so the search direction must satisfy

$$ \nabla f(x^{(k)})^T \Delta x^{(k)} < 0 $$

i.e., the search direction must make an acute angle with the negative gradient. Such a direction is called a **descent direction**.

#### General Descent Algorithm

```py
def descent_method(x):
    while not converged:
        delta_x = decent_direction()  # descent direction
        step = line_search()  # line search
        x = x + step * delta_x  # update
```

#### Exact Line Search

In **exact line search**, the step size $t$ is chosen to minimize $f$ along the ray $\{ x + t\Delta x | t \ge 0 \}$.

$$ t^* = \arg\min_s f(x + s \Delta x) $$

Can be used if solving the minimization of $t$ is cheap.

#### Backtracking Line Search

The step $t$ is chosen to approximately minimize $f$ along the ray, or just to reduce $f(x)$ "enough".

We 

```py
def backtracking_line_search(t_0, alpha, beta):
    t = t_0
    while (func(x + t * delta_x)
            > func(x) + alpha * t * gradient(x) * delta_x):
        t = beta * t
```

## Gradient Descent

A natural choice for the search direction is the negative gradient $\Delta x = -\nabla f(x)$. The resulting algorithm is called **gradient descent**.

```py
def gradient_descent(x_0):
    x_t = x_0
    while not converged:
        delta_x = -gradient(x_t)
        t = line_search()
        x_t = x_t + t * delta_x
```

The stopping criterion is usually of the form $\| \nabla f(x) \|_2 \le \eta$, where $\eta$ is a small and positive constant. The condition is checked after the first step (gradient computation), rather than after the update.

### Convergence Analysis

We assume $f$ is $m$-strongly convex and the condition number is $\kappa = \frac{M}{m}$, i.e.,

$$ mI \le \nabla^2 f(x) \le MI $$

Note that the upper bound $MI$ for the Hessian implies that

$$ f(y) \le f(x) + \nabla f(x)^T (y-x) + \frac{M}{2}\|y-x\|^2 $$

Minimizing RHS over $y$ yields

$$ f(y) \le f(x) - \frac{1}{2M}\| \nabla f(x) \|^2 $$

#### Analysis for Exact Line Search

$$ x^+ = x - t \nabla f(x), $$

where

$$ t = \arg\min_s f(x - s \nabla f(x)) $$

$$ \begin{align*}
    f(x^+) &= f(x - t \nabla f(x)) \\
    & \le f(x) - t\|\nabla f(x) \|^2 + \frac{Mt^2}{2}\|\nabla f(x) \|^2 \\
    & = f(x) + \|\nabla f(x)\|^2 (\frac{Mt^2}{2} - t)
\end{align*} $$

The RHS is a quadratic function of $t$, and is minimized by $t = 1/M$. Therefore,

$$ f(x^+) \le f(x) - \frac{1}{2M} \| \nabla f(x) \|^2 $$

Substracting $p^*$ on both sides

$$ f(x^+) - p^* \le f(x) - p^* - \frac{1}{2M} \| \nabla f(x) \|^2 $$

Recall that 

$$ f(x) - p^* \le \frac{1}{2m}\|\nabla f(x)\|^2 \Longrightarrow \| \nabla f(x) \|^2 \ge 2m(f(x) - p^*) $$

Therefore

$$ f(x^+) - p^* \le (1 - \frac{m}{M})(f(x) - p^*) $$

#### Analysis for Backtracking Line Search

Assume $\alpha = 1/2$ and $\beta \in (0, 1)$.

$$ \begin{align*}
    \tilde{f}(t) = f(x + t \Delta x) &\le f(x) - t\| \nabla f(x) \|^2 + \frac{Mt^2}{2} \| \nabla f(x) \|^2 \\
    &= f(x) + \| \nabla f(x) \|^2 (\frac{Mt^2}{2} - t)
\end{align*} $$

Note that $t \le 1/M$ satisfies the stopping criteria for the back tracking line search. Therefore, we have $t \ge \beta / M$. The back tracking stops either at $t = 1$ or some $t \ge \beta / M$. Therefore

$$ t \ge \min\{ 1, \frac{\beta}{M} \} $$

Since $t \le \frac{1}{M}$, $\frac{Mt}{2} \le \frac{1}{2}$, $\frac{Mt}{2} - 1 \le - \frac{1}{2}$, $(Mt/2 - 1)t \le -t/2$.

$$ \begin{align*}
    f(x + t \Delta x) &\le f(x) - \frac{t}{2} \| \nabla f(x) \|^2 \\
    &\le f(x) - \frac{1}{2} \min \left\{ 1, \frac{\beta}{M} \right\} \|\nabla f(x) \|^2
\end{align*} $$

Denote the $\min$ thingy by $c$. Recall (again) that $\| \nabla f(x) \|^2 \ge 2m(f(x) - p^*)$.

$$ f(x^+) \le f(x) -cm(f(x) - p^*) $$

Substract $p^*$ on both sides

$$ f(x^*) - p^* \le (1-cm)(f(x) - p^*) $$

## Steepest Descent Method

Consider the first order Taylor expansion

$$ f(x + v) \approx f(x) + \nabla f(x)^Tv $$

Define the **normalized steepest descent direction** (w.r.t. a norm $\|\cdot\|$) as

$$ \Delta x_{nsd} = \arg\min_v\{ \nabla f(x)^Tv | \|v\| \le 1 \} $$

### $L_2$-Norm

$$ \nabla f(x)^T v = \|\nabla f(x)\|_2 \cdot \|v\|_2 \cos\theta \ge - \|\nabla f(x)^T \|_2^2 $$

The steepest descent method for Euclidean norm coincides with the gradient descent method.

### Steepest Descent and Dual Norm

Note that

$$ \Delta x_{nsd} = \arg\min_v \{ \nabla f(x)^T v | \|v\| \le 1 \} $$

solves for the dual norm of $\nabla f(x)$.

## Newton's Method

<!-- - Newton's method is a steepest descent in a transformed space, corresponding to the $P$ norm in the original space.
  - If we use the Hessian as $P$, in the transformed space, the descent direction is an identity $I$, meaning that the method converges in one single step. -->

### The Newton Step

The **Newton step** for $f$ at point $x$ is given by

$$ \Delta x_{nt} = -\nabla^2 f(x)^{-1} \nabla f(x) $$

#### Interpretation of Newton Step

##### Minimizer of Second-order Approximation

The second-order Taylor expansion of $f$ at $x$ is

$$ \hat{f}(x+v) = f(x) + \nabla f(x)^Tv + \frac{1}{2} v^T\nabla^2f(x)v $$

which is a convex quadratic function of $v$. It is minimized when

$$ \nabla f(x) + \nabla^2 f(x) v = 0 \Rightarrow v = -\nabla^2 f(x)^{-1}\nabla f(x) $$

#### The Newton Decrement

Plug the Newton direction into the update step of the descent method.

$$ f(x+v) = f(x) - \frac{1}{2} \nabla f(x)^T \nabla^2 f(x)^{-1} \nabla f(x) $$

The quantity

$$ \lambda(x) = \left( \nabla f(x)^T \nabla^2 f(x)^{-1} \nabla f(x) \right)^{1/2} $$

is called the **Netwon decrement** at $x$.

### Newton's Method

```py
def newtons_method(x_0, eps):
    # x_0: initial value
    # eps: tolerance
    x = x_0
    while True:
        # compute Newton step
        hess = hessian(x)
        grad = gradient(x)
        x_nt = - inv(hess) @ grad
        decrement = grad.T @ inv(hess) @ grad
        # stopping criterion
        if decrement / 2 <= eps:
            break
        # line search
        t = backtracking_line_search()
        # update
        x = x + t * x_nt
```

### Convergence Analysis


