# 近似逼近方法

## 参数化价值函数

之前所有模型都是创建一个查询表，在表中维护状态价值函数 $V[s]$ 或动作价值函数 $Q[s,a]$。

- 处理大规模强化学习问题时
  - 状态空间或状态-动作空间可能非常大
  - 状态空间可能连续
- 解决方法
  - 离散化或分桶
  - 构建参数化的函数估计

## 离散化状态动作

- 对状态空间离散化
- 优点
  - 简洁直观
  - 高效
  - 在一些问题上能达到较好的效果
- 缺点
  - 过于简单
  - 一个桶只用一个常数，难以精确拟合连续函数
  - 维度灾难

## 参数化价值函数

构建可学习的函数来近似价值函数

$$ V_\theta(s) \approx V^{\pi}(s) \quad Q_\theta(s,a) \approx Q^{\pi}(s,a) $$

- 如果只关注参数化函数，那么绝大部分机器学习模型都可以使用
  - 线性模型、决策树等（需要特征工程）
    - 但是模型需要适合在非稳态、非独立同分布的数据上训练
    - 因此参数化模型比树模型更合适
      - 学出树模型后很难更改树的结构
  - 神经网络

### 随机梯度下降

#### 目标

找到参数向量 $\theta$ 最小化值函数近似值与真实值之间的均方误差

$$ J(\theta) = \mathbb{E}_\pi[\frac{1}{2}(V^\pi(s)-V_\theta(s))^2] $$

#### 梯度下降参数更新

$$ \theta = \theta - \alpha \frac{\partial J}{\partial \theta} = \theta + \alpha (V^\pi(s)-V_\theta(s))\frac{\partial V_\theta}{\partial \theta} $$

### 特征化状态

用一个特征向量表示状态

$$ x(s) = \begin{bmatrix}
    x_1(s)\\
    x_2(s)\\
    \vdots\\
    x_k(s)
\end{bmatrix} $$

## 价值函数近似算法

### 状态值函数近似

用特征的线性组合表示价值函数（也可以不用线性模型而用其他函数）

$$ V_\theta(s) = \theta^Tx(s) $$

$$ \theta = \theta + \alpha (V^\pi(s)-V_\theta(s))x(s) $$

#### 蒙特卡洛状态值函数近似

- 使用训练数据对价值函数进行预测

$$ (s_1,G_1), (s_2,G_2),\dots,(s_T,G_T) $$

- 对每个数据样本，使用梯度下降进行参数更新

$$ \theta = \theta + \alpha(G_t - V_\theta(s_t))x(s_t) $$

- 蒙特卡洛预测至少能收敛到一个局部最优解
  - 在价值函数为线性的情况下可以收敛到全局最优

#### 时序差分状态值函数近似

$$ (s_1,r_2 + \gamma V_\theta(s_2)), (s_2, r_3+\gamma V_\theta(s_3)), \dots $$

$$ \theta = \theta + \alpha (r_{t+1} + \gamma V_\theta(s_{t+1}) - V_\theta(s_t))x(s_t) $$

- 注意不需要对 $V_\theta(s_{t+1})$ 求梯度，因为它只是作为已知值，用于近似 $V^\pi(s)$

### 状态-动作函数近似

和 $V(s)$ 的近似类似，使用一个特征向量 $x(s,a)$ 表示特征，并对特征建立线性模型

$$ Q_\theta(s,a) = \theta^Tx(s,a) $$

#### 蒙特卡洛方法

#### 时序差分方法
