# Few-Shot Learning

## Problem Setting

- We are given a base category set $\mathcal{C}^b$ (each category has sufficient labeled samples)
- and a novel category set $\mathcal{C}^n$ (each category has only a few samples)
- Want to transfer knowledge to the novel set.

## Few-Shot Learning Methods

- **Meta-learning.** Learn a learning strategy to adjust well to a new few-shot learning task.
- **Metric learning.** Learn a semantic embedding space using a distance loss function.
- **Synthetic method.** Synthesize more data from the novel classes to facilitate regular learning.

### Meta-Learning

> *"Learn to learn."*

In meta-learning, we construct many tasks to train the model and hope it would generalize better when encountering new few-shot tasks.

#### N-way K-Shot Task

Construct multiple tasks to simulate the few-shot training process. Each task contains

- A training (support) set
  - $N$ categories
  - $K$ samples per category
- A test (query) set
  - Query samples in $N$ categories

#### MAML

> The high-level idea is to learn a good initial model that can quickly adapt to future tasks.

**Goal.** Optimize the model parameters such that *a small number of gradient steps on a new task will produce maximally effective behavior on that task.*

1. Randomly initialize $\theta$.
2. While not converged
   1. Sample batch of tasks $T_i \sim p(\mathcal{T})$
   2. For all $T_i$ do
      1. Evaluate $\nabla_{\theta} \mathcal{L}_{\mathcal{T_i}}(f_{\theta})$ w.r.t. $K$ samples
      2. Compute adapted parameters with gradient descent $\theta_i' = \theta - \alpha \nabla_{\theta} \mathcal{L}_{\mathcal{T_i}}$
   3. Update $\theta = \theta - \beta \nabla_{\theta} \sum_{T_i \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T_i}}(f_{\theta_i'})$.

- **Explanation.**
  - When adapting to a new task $T_i$, the model parameter $\theta$ is updated via gradient descent. $\theta_i' = \theta - \alpha \nabla_{\theta} \mathcal{L}_{\mathcal{T_i}}$.
  - The meta-objective loss is $\min_{\theta} \sum_{T_i \sim p(\mathcal{T})} \mathcal{L}_{\mathcal{T_i}}(f_{\theta_i'})$

### Metric Learning

Compare each testing data with training sample, and check whether the two samples belong to the same category.

#### Relation Network

- Concatenate embeddings of query and support samples.
- A relation module is trained to produce score 1 for correct class and 0 for others.

#### Matching Network

$$ P(\hat{y} | \hat{x}, S) $$

#### Prototypical Netowrk

- Learns a mapping function $f_\phi$ for extracting features.
- Construct class-level prototypes by using mapped representations, which is the centroid of each category.
  - $ c_k = \frac{1}{|S_k|} \sum_{(x_i, y_i) \in S} f_{\phi}(x_i) $
- At inference time, it performs non-parametric matching via distance $d$.
  - $p( y=k |x ) = \frac{\exp(-d(f_\phi(x), c_k))}{\sum_j \exp(-d(f_\phi(x), c_j))}$