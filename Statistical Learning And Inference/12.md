# Domain Adaptation

## Introduction

- The turning point of underfitting and overfitting depends on the difference in the distribution of the training and testing set.

### Data Distribution Mismatch

Denote the source domain (training set) and target domain (testing set) by $s$ and $t$.

The mismatch in source and target domains can be represented by

$$ p^s(x^s, y^s) = p^s(y^s | x^s) p(x^s) \quad \textrm{v.s.} \quad p^s(x^t, y^t) = p^t(y^t | x^t) p(x^t) $$

The differences can thus lie in

1. the marginal distribution $p^s(x^s)$ and $p^t(x^t)$.
2. the posterior distribution $p^s(y^s|x^s)$ and $p^t(y^t|x^t)$.

Most existing work focus on the marginal distribution.

### Domain Adaptation

Tries to adapt the model to the test set to achieve better performance.

- Different domains: different data sources, different devices for capturing data, different camera viewpoints.

## Labeled Source Domain + Unlabeled Target Domain

### Traditional Methods

#### Domain Invariant Projection (DIP)

Learn a projection matrix $W$ to project the samples from the source and target domains.

$$ d(W^TX_s, W^TX_t)^2 = \| \frac{1}{n_s} \sum_{i=1}^{n_s} \phi(W^T x_i^s) - \frac{1}{n_t} \sum_{i=1}^{n_t} \phi(W^Tx_i^t) \| = \mathrm{Tr}(K_WL) $$

where

$$ K_w = \begin{bmatrix}
    K_{ss} & K_{st} \\
    K_{ts} & K_{tt}
\end{bmatrix} $$

### Early Deep-Learning Methods

### GAN Methods

