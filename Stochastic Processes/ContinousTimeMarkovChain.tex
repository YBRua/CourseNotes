\chapter{Continuous Time Markov Chain}
\emph{“为了把连续的情况说清楚它还要发明一堆黑话。”}
\newpage


\section{Definition of Continuous Time Markov Chains}
    \subsection{Continuous Time Markov Chain}
        In the case of continuous time, it is technically difficult to specify the ``conditional probability given all of $X_r$ for all $r<s$''. Therefore instead, the Continuous Time Markov Chain is defined by

        \begin{definition}[Continuous Time Markov Chain]\label{def:ContinuousTimeMarkovChain}
            A stochastic process $X(t)$ is a \textbf{Continuous Time Markov Chain} if $\forall s,t \ge 0$, $\forall 0 \le s_0 < \cdots < s_n < s$
            \[ \mathbb{P}[X_{s+t} = j | X_s = i, X_{s_n} = i_n,\dots,X_{s_0}=i_0] = \mathbb{P}[X_t=j | X_0 = i] \]
        \end{definition}

        Given the current state, the previous states in the past is irrelevant for predicting the future, so we can simply ``throw away'' the previous states before $s$.

    \subsection{Transition Probability}
        In continuous case, the matrix-multiplication version of multistep transition probability cannot be applied directly. Instead we define a transition probability for each $t>0$.
        \[ p_t(i,j) = \mathbb{P}[X_t=j|X(0)=i] \]

        Recall the Chapman-Kolmogorov Equality \ref{thm:ChapmanKolmogorovEquality}, it still holds in the continuous case.

        \begin{theorem}[Chapman-Kolmogorov Equality, Continuous Case]\label{thm:ContinuousChapmanKolmogorovEquality}
            \[ \sum_{k}p_s(i,k)p_t(k,j) = p_{s+t}(i,j) \]
        \end{theorem}
        \begin{remark}
            This sugguests that if we know the transition probability for all $t<t_0$ (for some $t_0>0$), then we will be able to know the transition probability for all $t' \in \mathbb{R}$, by using the equality for sufficiently many times and keep doing the summation until $s+t=t'$.
        \end{remark}

        This further suggests that $p_t$ can be determined by its derivative at $t=0$.
        \begin{definition}[Jump Rate]\label{def:JumpRate}
            If the limit exists (assume it always does),
            \[ q(i,j) = \lim_{h \to 0}\frac{p_h(i,j)}{h} \quad \text{for $j \neq i$} \]
            then $q(i,j)$ is defined as the \textbf{jump rate} from $i$ to $j$.
        \end{definition}

    \subsection{A VERY Important Example}\label{sub:CTMCCoreExample}
        Let\footnote{“因为这个例子太重要了所以我给它起了个名字叫Example Star”--Chihao}
        \begin{itemize}
            \item $Y_n$ is a Markov Chain with transition matrix $u(i,j)$.
            \item $N(t)$ be a Poison Process with rate $\lambda$.
            \item $X(t)$ be a random variable defined as $X(t)=Y_{N(t)}$
        \end{itemize}
        That is, the discrete Markov chain $Y_n$ takes a jump according to the transition probability at each new arrival of the Poisson process $N(t)$.

        \subsubsection{Jump Rate of VERY Important Example.}
        By enumerating over all number of arrivals $n$
        \[ p_h(i,j) = \sum_{n=0}^\infty e^{-\lambda h}\frac{(\lambda h)^n}{n!} \cdot u^n(i,j) \]

        Notice that the probability of at least 2 jumps before time $h$ is 1 minus the probability of 0 and 1 jump,
        \[ 1 - (e^{-\lambda h}+\lambda h e^{-\lambda h}) \approx (\lambda h)^2/2! = o(h) \]
        So it converges to 0 when divided by $h$ and as $h \to 0$.
        Therefore
        \[ \frac{p_h(i,j)}{h} \approx \lambda e^{-\lambda h}u(i,j) \to \lambda u(i,j) \]


\section{More Examples}
    \subsection{The Poisson Process}
        Let $X(t)$ be the number of arrivals up to time $t$ in $Poisson(\lambda)$.

        Notice that at each new arrival, $X$ goes from $i$ to $i+1$ (with probability 1).
        
        Therefore $\forall n$
        \[ q(n, n+1) = \lambda \]

    \subsection{M/M/s Queue}
        We now consider a queue. Customers arrive according to a Poisson process of rate $\lambda$; the time to serve a customer is modeled by another Poisson process of rate $\mu$; there are only $s$ counters.

        Since the customers come in rate $\lambda$, we have
        \[ q(n, n+1) = \lambda \]

        Since the customers leave in rate $\mu$, we can use an exponential race in \ref{subs:ExponentialRace} to model the process, and therefore
        \[ q(n, n-1) = \begin{cases}
            \mu n & \quad n < s\\
            \mu s & \quad n \ge s
        \end{cases} \]


\section{Constructing a CT Markov Chain}
    \subsection{Informal Construction}
        Given a jump rate $q(i,j)$, the construction of a CTMC contains two steps, according to the formulation of \ref{sub:CTMCCoreExample}: 1) Choose $s\sim Exp(\lambda)$ to determine the next jump time, and 2) Choose $X(t+s) \sim u(i,\cdot)$ to determine the next state. Following this intuition, we define
        \[ \lambda_i = \sum_{j \neq i}q(i,j) \]
        $\lambda_i$ is the rate that the chain leaves $i$.
        \begin{itemize}
            \item If $\lambda_i = \infty$, then the chain leaves $i$ immediately.
            \item If $\lambda_i = 0$, then the chain will never leave $i$.
        \end{itemize}
        Since if the next state is chosen to be $i$, it is equivalent to state not moved, so we may choose different $\lambda_i$ so that in each jump we move into a different state. If we want identical $\Lambda$, we may choose $\Lambda = \sup \lambda_i$ and let $u(i,i)>0$.
        
        If $\lambda_i > 0$, let
        \[ u(i,j) = \frac{q(i,j)}{\lambda_i} \]
        be the probability that the chain goes to $j$ when it leaves $i$.

        \begin{itemize}
            \item If $X_t$ is in a state $i$ with $\lambda_i=0$, then the chain never leaves and we are done.
            \item If $X_t$ is in a state $i$ with $\lambda_i > 0$, then we first let the chain stay at $i$ according to an Exponential distribution with rate $\lambda_i$, then choose a destination according to $u(i,j)$.
        \end{itemize}


\section{Computing the Transition Probability}
    Given the jump rate $q(i,j)$, in the previous section we constructed a CTMC. In this section we move on to compute the transition probability.
    \begin{align*}
        p_{t+h}(i,j) - p_t(i,j) &= \sum_k p_h(i,k)p_t(k,j) - p_t(i,j) \quad \text{(CK Equation \ref{thm:ContinuousChapmanKolmogorovEquality})}\\
        &= \sum_{k \neq i} p_h(i,k)p_t(k,j) + (p_h(i,i)-1)p_t(i,j)\\
        &\triangleq A + B
    \end{align*}

    Multiply by $1/h$ and take limitation, then Expression A becomes
    \begin{align*}
        \lim_{h \to 0} \frac{1}{h}A &= \sum_{k \neq i}\lim_{h \to 0}\frac{1}{h}p_h(i,k)p_t(k,j)\\
        &= \sum_{k \neq i}q(i,k)p_t(k,j)
    \end{align*}

    and Expression B becomes
    \begin{align*}
        \lim_{h \to 0} \frac{1}{h}B &= \lim_{h \to 0}\frac{\sum_{k \neq i}p_h(i,k)}{h}p_t(i,j)\\
        &= \left(\sum_{k \neq i}q(i,k)\right)p_t(i,j)\\
        &= -\lambda_i p_t(i,j)
    \end{align*}

    And therefore
    \begin{equation}\label{eq:TransitionProbabilityKeyEq}
         \lim_{h \to 0}\frac{1}{h}\left(p_{t+h}(i,j) - p_t(i,j)\right) = \sum_{k \neq i}q_(i,k)p_t(k,j) - \lambda_i p_t(i,j) 
    \end{equation}

    Notice that the LHS of equation (\ref{eq:TransitionProbabilityKeyEq}) is the derivative of $p_t(i,j)$, and therefore
    \[ p'_t(i,j) = \sum_{k \neq i}q_(i,k)p_t(k,j) - \lambda_i p_t(i,j) \]

    Further notice that  hte first term $\sum_{k \neq i}q_(i,k)p_t(k,j)$ in RHS of (\ref{eq:TransitionProbabilityKeyEq}) can be re-written in a matrix multiplication. Let
    \[ Q(i,j) = \begin{cases}
        q(i,j) &\quad i \neq j\\
        -\lambda_i &\quad i = j
    \end{cases} \]

    And therefore
    \begin{equation}\label{eq:KolmogorovBackwardEquation}
        P'_t = QP_t
    \end{equation}
    This equation is also known as the \textbf{Kolmogorov Backward Equation}.

    This looks similar to a differential equation and the solution is
    \[ P_t = e^{Qt} = \sum_{n=0}^{\infty}\frac{(tQ)^n}{n!} \]
    where $e^{Qt}$ is defined as
    \[ e^Q = \sum_{n=0}^{\infty} \frac{Q^n}{n!} \]

    Furthermore, if we write $\sum_{k}p_t(i,k)p_h(k,j)$ instead of $\sum_{k}p_h(i,k)p_t(k,j)$ in the first step of derivation, we will end up with the \textbf{Kolmogorov Forward Equation}.
    \begin{equation}\label{eq:KolmogorovForwardEquation}
        P'_t = P_tQ
    \end{equation}

    \subsection{Example: Poisson Process Revisited}
        In the previous sections, we know that given the jump rate $q(i,j)$, we are able to compute the transition probability and simulate the continuous time Markov chain.

        Let $X(t)$ be the number of arrivals of a Poisson process up to time $t$. $p_t(i,j)$ is the probability that the number rises from $i$ to $j$ in time interval $t$. By definition of the Poisson process, the arrival between $0$ and $t$ has a Poisson distribution of rate $\lambda t$, and $p_t(i,j)$ is simply the probability that the number of arrivals between $0$ and $t$ is $j-i$.
        \[ p_t(i,j) = e^{-\lambda t}\frac{(\lambda t)^{j-i}}{(j-i)!} \]

        We can use the result to verify the forward and backward equation \ref{eq:KolmogorovForwardEquation} and \ref{eq:KolmogorovBackwardEquation}.

    \subsection{Example: Two State Markov Chain}
        Suppose there are only two states $\Omega = \{1,2\}$. The two-state continuous-time Markov chain can be specified by
        \[ q(1,2) = \lambda \quad q(2,1) = \mu \]
        and
        \[ Q = \begin{bmatrix}
            -\lambda & \lambda\\
            \mu & -\mu
        \end{bmatrix} \]

        By Kolmogorov backward equation \ref{eq:KolmogorovBackwardEquation},
        \[
        \begin{bmatrix}
            p'_t(1,1) & p'_t(1,2)\\
            p'_t(2,1) & p'_t(2,2)
        \end{bmatrix} = 
        \begin{bmatrix}
            -\lambda & \lambda\\
            \mu & -\mu
        \end{bmatrix}
        \begin{bmatrix}
            p_t(1,1) & p_t(1,2)\\
            p_t(2,1) & p_t(2,2)
        \end{bmatrix}
        \]

        Since there are only two states, it suffices to compute $p_t(1,1)$ and $p_t(2,1)$ only.
        \[ p'_t(1,1) = -\lambda p_t(1,1) + \lambda p_t(2,1) \]
        \[ p'_t(2,1) = \mu p_t(1,1) - \mu p_t(2,1) \]

        Therefore
        \[ \left(p_t(1,1)-p_t(2,1)\right)' = -(\lambda + \mu)\left(p_t(1,1)-p_t(2,1)\right) \]

        Solving the differential equation gives us
        \[ p_t(1,1) - p_t(2,1) = e^{-(\lambda + \mu)t} \]

        Plug the result back into the expression for $p'_t(1,1)$,
        \[ p'_t(1,1) = -\lambda e^{-(\lambda + \mu)t} \]

        Integrate over $t$
        \[ p_t(1,1) = p_o(1,1) - \lambda\int_0^t e^{-(\lambda + \mu)s}\mathrm{d}s = \frac{\mu}{\mu + \lambda}+\frac{\lambda}{\mu + \lambda} e^{-(\lambda + \mu)t} \]


\section{Limiting Behaviour: Continuous Time}
    \subsection{Irreducibility, Continuous Case}
        The intuition remains the same: the chain can jump from any state $i$ to any state $j$ in finite steps.
        \begin{definition}[Continuous Time Irreducibility]
            A continuous-time Markov chain is \textbf{irreducible} if there exists a sequence $k_0 = i, k_1, \dots, k_n=j$ such that
            \[ q(k_{m-1},k_m) > 0 \quad \forall 1 \le m \le n \]
        \end{definition}

        \begin{lemma}\label{lem:NecessaryConditionOfIrreducibility}
            If $X(t)$ is irreducible and $t>0$, then
            \[ p_t(i,j) > 0 \quad \forall i,j \]
        \end{lemma}

    \subsection{Stationary Distribution}
        \begin{lemma}[Stationary Distribution, Continuous Case]\label{lem:ContinuousTimeStationaryDistribution}
            A distribution $\pi$ is a stationary distribution if and only if
            \[ \pi^T Q = 0 \]
            or equivalently, iff
            \[ \pi^T P_t = \pi^T \quad \forall t \]
            but this one is difficult to verify.
        \end{lemma}
        \begin{remark}
            Using the definition of $Q$ we can prove that
            \[ \sum_{i \neq j}\pi(i)q(i,j) = \lambda_j\pi(j) \]
            The LHS is the rate that the chain ``gets into'' state $j$, and the RHS is the rate that the chain ``gets out of'' state $j$. So the intuition of continuous-time stationary distribution is that the rate that a chain goes in and goes out of a state are equal.
        \end{remark}

    \subsection{Convergence}
        \begin{theorem}[Convergence of CT Markov Chain]\label{thm:ConvergenceOfCTMarkovChain}
            If a continuous time Markov chain is irreducible and has a stationary distribution $\pi$, then
            \[ \lim_{t\to\infty}p_t(i,j) = \pi(j) \]
        \end{theorem}
        \begin{remark}
            Notice that we are not considering ``aperiodicity'' in CTMC, because a CTMC always has self-loops.
        \end{remark}

    \subsection{Detailed Balance Condition, Continuous Case}
        \begin{theorem}[Detailed Balance Condition]\label{thm:DetailedBalanceConditionOfCTMarkovChain}
            If
            \[ \forall i \neq j \quad \pi(i)q(i,j) = \pi(j)q(j,i) \]
            then $\pi$ is a stationary distribution.
        \end{theorem}
