# 物理内存管理

## 物理内存管理概述

### 什么时候考虑物理内存

引入虚拟内存后，物理内存主要出现在以下四个场景

1. 用户态程序出现 `Page Fault`
   - VMA合法，但是页表项的valid bit标识符并不合法
   - 需要找到空闲的物理页、分配页表并重新执行访存代码
2. 内核自己申请内存并使用时
   - 使用 `kmalloc` 函数完成
     - 用时分配、用完释放，类似用户态的 `malloc`
     - 申请到的内存可能**比页的粒度更细**
   - 出于性能考虑，与 `malloc` 机制不同，不会按需分配内存页
     - 不希望在kernel触发Page Fault
     - 要求分配内存时，就**已经完成映射**
3. 内核申请用于设备的DMA缓存
   - 设别绕过CPU直接访存
   - 通常需要大段连续的内存
   - 要求操作系统有能力分配连续的物理页
4. 换页（Swapping）时
   - 需要实现换入、换出操作
   - 换出时，需要根据特定策略选择不常用的物理内存页、将数据写入磁盘块、建立物理页和磁盘块的关联，并更新页表
   - 换入时，需要找到被换出页对应的磁盘块、分配空闲的物理页（如果没有，则需要再次换出）、写入空闲物理页并更新页表项

### 内核物理内存管理的需求与评价指标

#### 需求概述

- 管理所有空闲的物理页，要求内核有能力分配一个或多个连续物理页
- 管理所有已分配的内存页，要求内核能随时回收已分配的页，并将其恢复为空闲页

#### 物理内存管理的评价指标

- 资源利用率
  - 避免内部碎片和外部碎片
- 分配速度
  - 要求内存分配与释放操作的低时延
- 分配公平性
  - 要求避免某些应用独占大量内存

### 内存碎片

#### 内部碎片

- 当分配的内存空间大于实际分配请求所需要的，就会造成部分内存的浪费

#### 外部碎片

- 如果一个内存管理系统很糟糕，外部碎片通常会在多次内存分配和回收后产生
- 物理内存上的空闲部分离散地分布在物理内存空间
- 虽然空闲内存总和足够，但是残余的空闲部分可能小于一次内存分配请求，造成内存分配失败

### 直接映射机制

- 一次性将所有物理内存映射到一段虚拟地址空间
  - 物理地址和虚拟地址之间只相差一个偏移量
    - 可以快速进行物理地址和虚拟地址的映射
  - 类似最早期的内存分配机制，但是实际通过配置页表实现
- 特点
  - 内核使用直接映射的虚拟地址，不会触发`Page Fault`
  - 可以更方便地找到连续的物理页
  - 内核并没有占有这段空间，只是建立了映射关系便于查找
  - 内核需要使用时仍然要调用 `kmalloc` 分配内存
  - 但是与一般应用程序不同，内核可以直接访问映射范围内的任何地址（而不会触发 `Segmentation Fault`）

#### 对于内核

- 已经映射的地址不一定正在使用（需要`kmalloc`后才能用）
- 正在使用的地址通常已经映射
  - 例外：使用`vmalloc`分配内存，`vmalloc`行为类似用户态的`malloc`

#### 对于应用

- 正在使用的地址（已有VMA）不一定已经有映射（按需分页）
- 已经映射的地址一定正在使用（否则不会被映射）

#### 直接映射机制下的虚拟地址

- 同一个物理地址可能有多个虚拟地址
  - 应用程序下任意一个已经映射的虚拟地址，在内核的直接映射下也有一个虚拟地址

## 伙伴系统

### 空闲物理内存的简单管理方法

- 通过bitmap记录物理页是否空闲
- 分配时，找到空闲的物理页，并在bitmap中标记为非空闲
- 回收时，在bitmap中把对应页标记为空闲

#### 问题

- 如果只考虑以“页”为粒度的分配，则没有问题
- 但是要分配大段连续内存时，可能造成外部碎片，且查找效率较低

### 伙伴系统 Buddy System

```mermaid
graph TB
    32K---16KA
    32K---16KB
    16KA---8KA
    16KA---8KB
    16KB---8KC
    16KB---8KD
    8KA---4KA
    8KA---4KB
```

#### 概述

- 将物理内存划分为连续的**块**
  - 每个块由一个或多个连续的物理页组成
  - 以块为单位进行内存分配
- 伙伴系统要求每个块中包含的物理页数量必须是2的整数次幂（$0\le n \le M$）
  - 预设的最大值 $M$ 决定了可以连续分配的物理页的最大大小

#### 分裂与合并

- 一个伙伴块可以分裂为下一级的两个伙伴块
- 两个连续伙伴块可以合并成一个上级伙伴块

#### 分配

- 当一个请求需要$m$个物理页时，伙伴系统将寻找一个合适的块，该块包含 $2^n$ 个物理页，且$2^{n-1} < m \le 2^n$
- 释放时，OS会找到被释放块的伙伴块，如果伙伴块为空闲状态，则直接合并
  - 由于合并操作是级联的，因此可以很好地缓解外部碎片问题

#### 基于链表的伙伴系统实现

- 使用链表，第$n$个节点记录 $2^n$ 大小的块
- 需要分配内存时
  - 先查找最合适的大小的节点是否为空
    - 即有无可分配的块
  - 如果有则分配
  - 没有则查找更大的节点，并将更大的节点分裂成合适的大小

#### 伙伴机制的特点

- 可以高效地找到伙伴块
  - 互为伙伴地两个块只有1位地址不同
  - 且块的大小决定了哪一位地址不同

#### 优势与弊端

- 优势
  - 缓解外部碎片问题
  - 可以快速查找同层的伙伴页，使合并机制性能提高
- 问题
  - 一次内存页释放可能导致大量合并操作，造成时间开销
  - 内部碎片依然存在

## SLAB/SLUB/SLOB：细粒度内存管理

内核大量数据结构都只有几十Byte，直接分配一个4KB的页会导致内存利用率极低，造成严重的内部碎片，因此需要更细粒度的内存管理

### SLAB 分配器家族

- 目标：快速分配小内存对象
- 从最初的SLAB开始逐渐演进产生SLUB、SLOB等后继实现
- 以主流的SLUB为例

SLUB系统的初衷是满足操作系统频繁地分配小对象的需求，其依赖于伙伴系统提供的物理页分配机制

### 基本思路

- 操作系统频繁分配的对象的大小相对比较固定
- 从操作系统获得大块内存（称为一个slab）
- 把一个slab进一步细分为固定大小的小块（slot）内存进行管理
- 块的大小通常是$2^n$字节
  - $3 \le n < 12$

### SLUB设计

- 只分配固定大小的块
- 对每组固定大小的块（32B、64B、128B等），SLUB使用独立的资源池进行分配
- 采用best-fit策略选择合适的资源池
  - 例如`14Byte`的使用`16B`块，`17Byte`的使用`32B`块

#### 空闲链表

- 使用空闲链表组织一组固定大小的空闲块
- 分配时，先找到合适的大小，然后取走链表头指向的内存小块
- 若当前大小的块已经全部分配完，则从伙伴系统申请一个新的slab并划分成slot继续分配
- 释放时，根据被释放object的地址找到当前slab的起始地址即可

### 总体架构

- 三个指针
  - `current` 指向一个空闲的slab
    - 所有的分配请求都将通过 `current` 指针指向的slab获取空闲块
    - 有效避免外部碎片，同时保证了性能（只需要从 `current` 指向的 slab 获取第一个空闲块）
  - `partial` 指向所有未满的slab
  - `full` 指向所有已经分配完的slab
- 分配时使用 `current` slab
  - 若满则当前slab移动到 `full`
  - 然后从 `partial` 里抓一个 slab 作为新的 `current`
  - 如果没有空余的 `partial`，则重新申请一个全新的slab放到 `current`
- 释放时释放到对应slab
  - 如果一个 `full` 的slab的一个slot得到释放，则移动到 `parital`
  - 如果一个slab释放完之后全部都是空闲块，则可以将这个slab归还给伙伴系统

### 小结

#### 伙伴系统

- 分配单个或连续的物理页
- 缓解外部碎片

#### SLUB

- 分配比页小的内存请求
- 缓解内部碎片

## 换页策略

分配物理页时，若空闲的物理页已经用完，或者不足以满足分配需求，则操作系统将根据特定的换页策略选择一个或多个~~倒霉蛋~~物理页换出到磁盘以便让出空间。

当已经被换出的物理页被再次访问时，将会需要从磁盘重新写回内存（甚至可能引起另一次换页），因此换页策略将影响系统性能。

### 理想策略（OPT）

#### 策略

- 假如已知完整的物理页面访问顺序，则从最小化缺页异常的角度
  - 先替换不再使用的页
  - 再替换短时间内不再使用的页

#### 问题

- 只是理想情况的解决方案
- 实际上操作系统无法知道完整的物理页面访问顺序

### FIFO策略

> “做Lab不考虑性能的时候可以用”

#### 策略

- 维护一个队列
- 先读入的物理页面先被替换

#### 问题

- 性能问题
  - Belady's Anomaly
    - 物理页增加反而可能导致某些情况下效率下降
- “因此也几乎不会被现代操作系统直接使用”

### Second Chance

#### 策略

- 从FIFO策略改进
  - 同样维护一个先入先出的队列
- 为每个物理页号维护一个访问标识
- 如果访问的页面号已经处于队列中，则置上其访问标识位
- 换页时仍然查看队头
  - 如果没有标识位，则换出
  - 否则去除标识并将其放入队尾，继续寻找
- 同样有可能遭遇Belady's Anomaly

### Least Recent Used LRU

#### 策略

- 维护一个链表
- 每次内存访问后，把刚访问的内存页调整到链表尾端
- 每次都选择换出链表头部的页面

#### 问题

- 对于特定序列，效果可能非常差（例如循环访问内存）
- 需要排序的内存页可能非常多，会造成额外负载

#### 实现

- 在应用程序运行时，应用程序占用了CPU
- 因此OS此时不在运行
- 因此OS并不知道应用程序访问了哪些页
- 因此对页访问的监控需要依赖硬件
- 实现开销往往较大

##### 精准排序

- CPU在访问某个页时，在页表项上大时间戳
- OS遍历每个内存页的页表项，根据时间戳排序
- 缺点
  - 遍历所有页表项过于费时
  - 在有多个CPU时，不同CPU的时间戳不一定能全局排序，无法保证完全精确

### 时钟算法

- LRU精准排序的近似实现
- 物理页组织成一个环形队列
- 每个物理页页表项中有一个访问位 `AccessBit`
- OS把所有 `AccessBit` 抹去为 `0`
- 然后交给 CPU，每当物理页被访问时，CPU将 `AccessBit` 设为 `1`
- 当需要踢出一页时，操作系统按序访问页表
  - 如果 `AccessBit` 为 `1`，则置零
  - 否则踢出该页
- OS只需要维护一个指针，标记当前扫描到哪里
  - 换页时不需要遍历整个页表
  - 扫描到第一个 `0` 即可
- 如果所有 `AccessBit` 均为 `1`，则遍历一圈后会访问到 `0`

#### 反向映射

- 在踢出一个物理页后，需要修改所有页表中映射到该物理页的虚拟页
- 当物理页被填写到某张页表时，把页表项的位置记录在元数据中
  - Linux 中称为 Reverse Mapping
- 根据物理页对应的页表项中的 `AccessBit` 判断是否要驱逐该项
- 踢出该页时清空所有对应的页表项

!!!note
    在实际应用中找不到 one-size-fit-all 的策略。但是 LRU 在大部分情况下的表现都很良好。

## 工作集模型

### 颠簸现象 Thrashing Problem

- 直接原因
  - 对物理内存的需求过大，导致频繁的缺页异常
  - 比如选择的换页策略和实际的工作负载不匹配，在循环访存时不幸地使用了LRU等
- 导致大部分CPU时间都被用来处理缺页异常
  - 等待缓慢的磁盘读写
  - 只有少部分时间在执行真正有用的计算操作
- 调度器使问题加剧
  - CPU等待磁盘读写导致CPU利用率下降
  - 调度器载入更多进程，以期提高CPU利用率
  - 结果造成更多缺页异常，陷入恶性循环

### 工作集

- $W(t,x)$ 表示进程在 $[t-x, t]$ 时间段内使用的内存页集合
- 也用于估计该进程在下一个 $x$ 时间段内将要使用的内存页集合
  - 即使用过去的内存页访问记录预测未来可能的内存访问
- All-or-Nothing
  - 一个进程的工作集要么完整地保存在物理内存中，要么整个从物理内存中换出
- 现代操作系统很少直接使用all-or-nothing作为换页原则，但是工作集的概念仍然主导这换页策略：即优先将非工作集的物理页换出

#### 跟踪工作集

- 工作集时钟中断固定间隔发生，调用处理函数扫描内存页
- 若某页访问位为 `1`，则$上次使用时间$为当前 $tick$
- 若某页访问位为 `0`，则 $Age = tick - 上次使用时间$
  - 若 $Age > x$，则该页不在工作集中
- 最后，OS将所有访问位清零
  - 该实现需要CPU在硬件实现上能够支持在访存时自动地将某个页的访问位设为 `1`
