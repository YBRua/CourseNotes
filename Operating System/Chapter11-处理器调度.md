# 处理器调度

## 调度概述

调度器从任务队列中选择任务，放置到对应的CPU上执行

```mermaid
graph LR
    任务队列-->调度器
    调度器-->|Task1|CPU0
    调度器-->|Task2|CPU1
```

### 调度决策

- 下一个要执行的任务
- 执行任务的CPU
- 执行的时间

### 执行结束

- 执行时间结束
- 系统调用
  - 等待I/O
- 睡眠
- 中断
- ...

### 不同场景下的调度目标

- 批处理程序：高吞吐
- 交互式应用：低响应时间
- 网络服务器：可扩展性
- 移动设备：低功耗
- 实时系统：实时性

### 调度器的目标

- 降低周转时间：任务进入系统到执行结束的时间
- 降低响应时间：任务进入系统到第一次给用户响应的时间
- 实时性：在截止时间内完成任务
- 公平性：每个任务都应该有机会执行
- 开销低：优化系统，而不是增加资源占用
- 可扩展：随着任务增加仍能正常工作
  - “两百个lab下来，大家就崩溃了。不work了。”

## 经典调度

### 先到先服务 First Come First Served

- 简单、直观
- 平均周转、响应时间过长
- 常见于批处理应用场景

### 短任务优先 Shortest Job First

- 平均周转时间短
- 平均响应时间过长
- 不公平，任务饿死（starvation）

### 抢占式调度 Preemptive Scheduling

- 每次任务执行一段时间后会被切换到下一个任务
- 通过定时触发的时钟中断实现

#### 时间片轮转 Round Robin RR

- 每个进程运行一个时间片
- 公平、平均响应时间短
- 牺牲了周转时间
  - 每个进程的运行时间被“拉长”
  - 周转时间问题在耗时接近的任务同时到达时最为显著

##### 时间片长度

- 时间片太长会导致响应时间变长
- 时间片太短会造成频繁切换，导致周转时间变长

## 优先级调度

- 操作系统中的任务优先级是不同的
  - 系统、用户
  - 前台、后台
- 优先级用于确保重要的任务被优先调度
- 事实上FCFS和SJF也有优先级概念；RR中优先级的概念较弱

### 多级队列 Multi Level Queue

- 维护多个队列，每个队列静态设置好优先级
- 高优先级的任务优先执行
- 同优先级内使用 RR 调度

### 问题

- 资源利用率低
  - 例如多个低优先级的任务要访问IO时，将会导致低优先级的任务等着依次访问IO而CPU没有任务
  - 本质上还是优先级设置的问题

### 高优先级的任务

- IO密集型任务
  - 占用CPU时间少，在该任务访问IO时可以处理其他任务
- 用户主动设置的重要任务
- 对时延要求极高的任务

### 优先级的动态调整

- 操作系统中的工作场景动态变化
- 静态的优先级不一定能灵活适应场景变化

#### 优先级反转

- 高优先级的任务被低优先级的任务阻塞
  - 例如低优先级的任务C先访问了IO
  - 导致IO资源被C抢占
  - 同样需要访问IO的高优先级任务A只能等待C完成IO访问
  - 同时不需要访问IO的任务B占用了CPU，导致C访问完IO后无法执行
  - 进而导致优先级最高的A一直无法执行
- 结果造成高优先级的任务等待低优先级的任务

```mermaid
sequenceDiagram
    activate C
    Note left of C: C申请IO
    C->>A: .
    deactivate C
    activate A
    Note right of A: A在C之后申请IO，等待C结束IO
    A->>B: .
    deactivate A
    activate B
    B->>A: 导致A需要等C，C需要等B
    deactivate B
    Note right of B: B优先级高于C，优先执行
```

##### 动态优先级继承

- A将优先级暂时转移给C，让C尽快完成

```mermaid
sequenceDiagram
    activate C
    Note left of C: 申请IO
    C->>A: .
    deactivate C
    activate A
    Note right of A: A比C晚申请IO，等待C结束IO
    A->>C: .
    deactivate A
    activate C
    Note right of A: A将优先级转让给C
    C->>A: .
    deactivate C
    Note left of C: IO结束，C将优先级返还给A
    Note right of B: 没有B什么事情
```

## 多级反馈队列

### 特点

- 无需先验知识的通用调度策略
- 周转时间低、响应时间低
- 调度开销低

### 概述

- 动态分析任务运行历史，总结任务特征
  - 类似思想：分支预测、缓存
- 如果工作场景变化频繁，则效果可能会很差

### 基本算法

- 有8个不同优先级
- 优先级高的任务会抢占优先级低的任务
- 每个任务会被分配时间片，优先级相同的任务按照RR调度
- 每个任务被创建时，假设该任务是短任务，为它分配最高优先级
  - 一个短任务在短暂的CPU访问后会放弃CPU（例如去访问IO）
  - 例如 MacroHard OnFire Word
    - 大部分时间在等用户输入
    - “只有用word的人会摸鱼，word不会摸鱼”
- 一个任务时间片耗尽后，它的优先级会被降一级
- 如果一个任务在时间片耗尽前放弃CPU，则优先级不变
  - 任务重新执行时，会被分配新的时间片

#### 问题

- 长任务饿死
  - 大量短任务和IO密集型任务可能占用所有CPU时间
  - “比如说我们放10个电影——谁会同时放——呃我们先不管”
- 任务特征可能动态变化
  - 从CPU密集任务转换为交互式任务

### 定时优先级提升

- 在某个时间段S后，将系统所有任务优先级重新提到最高
- 避免长任务饿死
- 可以适应人物特征动态变化
- 细节
  - S长度
  - 时间片长度

#### 问题

- 无法应对抢占CPU时间的攻击
  - 恶意任务在时间片用完之前发起IO请求
  - 按现有规则，不会被降低优先级，但是几乎独占了所有CPU资源

### 更准确记录执行时间

- 一个任务的累计执行时间超过一个任务时间片后，降低任务优先级
  - 无论这期间任务放弃了多少次CPU
- 额外记录任务在当前优先级累计使用CPU的时间长度

### MLFQ参数调试

> “系统调参通常还是可解释的”

- 不同场景下，不同参数会有不同表现

#### 不同队列的时间片长度

- 高优先级的队列对应的时间片短一些
  - 提升高优先级任务的响应时间
  - 降低低优先级任务的调度开销
    - 反正大家都在吃CPU，换来换去也没意思（bushi

### 小结

- 无需先验知识即可动态确定任务优先级
- 同时达到周转时间和响应时间两方面要求
  - 对于短任务，周转时间指标接近SJF
  - 对于交互式任务，响应时间指标接近RR
- 避免长任务饿死

## 公平共享调度

- 应用场景：共享服务器
- 注重用户级的公平，而非任务级的公平
  - 每个用户占用的资源是和用户各自的权重成比例的，而非被任务数量决定

### 彩票调度 Lottery Scheduling

> “彩票，大家知道，是公平的”
> “……”
> “理想彩票。”

- 每次调度时，生成随机数 $R \in [0,T)$
  - $T$ 是 $ticket$ 总数
  - 每个任务 $i$ 有各自的 $ticket_i$
  - $ticket_i / T$ 表示任务 $i$ 可以占用CPU的时间比例
- 根据 $R$ 找到对应的任务
- 例如 ABC 三个任务的 $ticket$ 分别是 20、30、50，在$R=51$时执行任务C
- 只能期望它是公平的（x

#### Ticket Transfer

- 场景
  - 客户端等待服务端返回才能继续执行
  - 客户端等待通信
- 客户端将自己的所有ticket移交给服务端，确保服务端尽可能多享用资源

与优先级传递类似，但是两者不同

- 权重影响对CPU的占用比例
  - 除非权重为0，否则任务不会饿死
  - 权重10:1和2:1决定了两个任务占用CPU的比例
- 优先级影响任务对CPU的使用顺序
  - 可能导致任务饿死
  - 优先级10:1和2:1只影响顺序，不影响比例

#### 彩票调度的利弊

- 简单
- 计算机采用伪随机，不精确
- 各个任务对CPU时间的占比会有误差

### 步幅调度 Stride Scheduling

- 确定版本的彩票调度

#### 步幅

- 任务执行一次增加的虚拟时间

$$ stride_i = \frac{MaxStride}{ticket_i} $$

- $MaxStride$ 是一个足够大的整数
  - 例如所有 $ticket$ 的最小公倍数
    - 此时 $stride$ 和 $ticket$ 成反比

#### 步幅调度

- 每次调度时，选择累计运行 $stride$ 最短的任务
- 虽然每个任务每次运行的物理时间是一样的，但是 $stride$ 不同
- $ticket$ 高的任务 $stride$ 累计更慢，更容易被执行到
- “步幅”可以理解为“虚拟时间”
  - OS人很喜欢虚拟.jpg

## 实时调度

- 每个任务有截止时间
- 软实时
  - 超过截止时间不会有非常严重的后果
  - 例如视频渲染，超时导致帧数下降
- 硬实时
  - 超过截止时间会有严重后果
  - 例如自动驾驶，超时就寄了

### 最早截止时间优先 Earliest Deadline First

> 广大人民群众最喜欢的经典算法

- $C_i$：任务所需的执行时间
- $P_i$：任务触发的时间周期
  - 同时假设 $P_i$ 是任务的截止时间
  - 例如一个月一次、一次一个月的强化学习小作业

#### EDF可调度的条件

$$ \sum_{i=1}^n \frac{C_i}{P_i} \le 1 $$

- “大家回去可以自己算一下，如果大于一，那可能得少睡一些”
- 如果超过1，则可能需要拒绝新的任务
- 一旦有任务超过deadline，可能导致后续多个任务也都超过deadline

## 上下文切换

- 现代分时操作系统让进程轮流使用CPU资源
  - 进程需要不断重复暂停、恢复、暂停的过程
  - 为了正确执行，需要引入上下文和上下文切换

### 概述

#### 上下文切换的流程

1. 进入内核
2. 保存上下文
3. 切换
4. 恢复上下文
5. 离开内核

#### 需要保存的信息

假如在关机重启后想要恢复一个进程，则需要保存

- 用户态内存空间
- 内核态内存空间中关于进程的信息
  - 进程控制块 PCB
- CPU中的若干寄存器
  - 例如 `SP`、`PC`、`PSTATE` 等

都是如果只是进程切换（不关机），则

- 内核态的信息可以不用保存
- 用户态的内存也不需要保存
  - 只需要切换页表指针寄存器
- 在CPU中仍然有若干寄存器需要保存
  - `TTBR0`、`PC`、`SP`、`PSTATE`、GPR `x0-x30`

### 用户态/内核态切换

#### 切换到内核态

- `PSTATE` 写入 `SPSR_EL1`
- `PC` 写入 `ELR_EL1`
- 栈指针切换到 `SP_EL1`
  - 内核不能使用用户态的栈
  - 通常每个进程有和自己单独绑定的一个内核栈
  - 隔离用户态和内核态
- 页表切换到 `TTBR_1`
- 运行状态切换到EL1
- `PC` 移动到内核异常向量表

#### 返回用户态

- 切换到内核的逆过程，AArch64提供了硬件支持
- `SPSR_EL1` 切换到 `PSTATE`
- `ELR_EL1` 重设到 `PC`
- 页表切换到 `TTBR_0`
- 运行状态切换回 `EL1`

#### 问题

- 通过支持内核态/用户态切换，可以实现让进程进入内核态并返回
- 该机制不足以直接实现上下文切换
- 不同进程地址空间不同，使用的寄存器值也不同
- 寄存器只有一套，直接切换会导致错误
- 需要将信息保存到内存
  - 该功能交给软件实现

### 上下文保存与恢复的软件实现

- 与进程相关的三种内核数据结构
  - PCB、上下文、内核栈
- PCB保存指向上下文的引用
- 常用实现是将上下文位置固定在内核栈底部

#### ChCore实现

- 上下文保存
  - 在完成用户态/内核态切换、进入内核态之后
  - 将各个寄存器逐个压入内核栈中
    - `x0-x30`、`SP_EL0`、`ELR_EL1`、`SPSR_EL1`
- 上下文恢复
  - 将内核栈中的寄存器全部弹出，恢复到寄存器中

### 上下文切换的实现

- 从p0切换到p1，涉及两个关键步骤
  - 切换到p1的地址空间
  - 切换到已经存储好的p1上下文并进行恢复
- 关键在于切换栈指针，从p0的栈切换到p1的栈
