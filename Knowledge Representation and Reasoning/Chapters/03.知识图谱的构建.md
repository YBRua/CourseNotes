# 知识图谱的构建

## 命名实体识别

- 从文本中识别出代表实体的边界，并进一步判断其类别
- 关系抽取、事件抽取任务的基础

### 方法

#### 基于规则

- 基于文本与规则进行匹配
- 准确；且有些命名实体只能依靠规则抽取；适用于半结构化数据
- 需要大量语言学知识；需要处理规则的冲突；可维护性差、可移植性不强

#### 基于统计模型

- 建模为序列标注任务

##### BIO标签体系

- Begin：命名实体开头
- Inside：命名实体中间
- Outside：与命名实体无关

##### BIOES标签体系

- End：命名实体结尾
- Singleton：单个token作为一个命名实体

#### 基于神经网络模型

- 通过 BiLSTM / CNN / BERT 等模型（通常是神经网络编码器）生成用于实体识别的句子特征
- 通过条件随机场、Softmax等解码器生成序列标注标签

### 词汇增强

#### 中文命名实体识别

- 边界较难判别
- 嵌套实体较多
  - 复旦大学附属第五人民医院
- 用字变化多，同一实体在不同语境可能是不同类型

#### Lattice LSTM

- 通过词汇表和句子匹配得到 word-character lattice （句子中词汇和字符的对应关系）
- 编码字符时，额外融合来自不同路径的信息

##### 缺陷

> “我觉得大家可能一天都调不出来”

- 实现复杂
- 计算性能低下，较难并行
- 每个字符只能获得以该字符结尾的词汇的信息

#### Collaborative Graph Network CGN

1. 分别编码字和词
2. 输入 *图编码层* 进一步编码
3. 输入 Fushion 层
4. 经解码器输出

##### 图编码层

图编码层定义了不同的 Lattice 连接模式

1. 字符之间无连接，词与其内部的字有链接
2. 相邻字符相连接，词与其前后的字有连接
3. 相邻字符相连接，词与其开头结尾的字有连接

#### FLAT

- 在注意力计算中加入相对位置编码的偏置

相对位置的计算方法基于字词的相对位置

- 在输入时（一般情况下）可以抛弃绝对位置编码
  - 位置编码被替换为 head 和 tail 两个编码
  - head是当前字（或词）在句中的起始位置
  - tail是当前字（或词）在句中的结尾位置
- 根据起始终止位置的相对位置选择对应的相对位置向量

### 嵌套实体识别

- 嵌套的命名实体难以通过序列标注建模

#### Multi-Grained Named Entity Recognition MGNER

- 将命名实体的 **识别** 与 **分类** 分开处理

##### 识别网络

- 假设命名实体的有一个最大长度 $L$ （论文中为 6）
- 预定义了一些长度不超过 $L$ 的 Pattern （类似滑窗？）
- 对每个 Proposal，计算分数判断其是否可能是一个命名实体
- 如果是，则再进一步分类

输入是词嵌入、词性嵌入和字符嵌入（缓解OOV）
