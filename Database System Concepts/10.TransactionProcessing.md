# Transaction Processing

## What is a Transaction

A **transaction** is a collection of operations that performs a *single* logical function in a database application.

### Transaction in SQL

```sql
BEGIN TRANSACTION
    /* ... subsequent SQL operations */
COMMIT /* or  ABORT/ROLLBACK */ 
```

- The transaction statement begins with `BEGIN TRANSACTION`
- Ends with `COMMIT` or `ABORT/ROLLBACK`
  - `COMMIT`: Makes all the changes permanent and visible to all other transactions
  - `ABORT/ROLLBACK`: Reverts the effects of the transcation
- Most DBMS have an **autocommit** mechanism that automatically turns each statement into a transaction

### Transaction States

- **Active**: The initial state.
  - The transaction stays in this state while it is executing, and turns into one of the four following states
- **Partially Committed**: After the final statement has been executed
  - It is still possbile that a transaction in this state still has to be aborted, because is has not committed, and the output may still be in the main memory
- **Failed**: After the discovery that normal execution cannot be continued
  - The transaction will then be rolled-back and either restarted or killed
- **Aborted**: After the transaction has been rolled back and the database is in its initial state, before the start of this transaction.
- **Commited**: After a successful execution

### ACID Properties

- **Atomicity**: Either all operations in a transaction happen, or none of them happens (all-or-nothing).
- **Consistency**: Execution of a transaction in isolation perserve the consistency of the database (correctness).
- **Isolation**: Each transaction must be unaware of other concurrently executing transactions (as if alone).
- **Durability**: Effects of commited transactions are resilient against failures (recoverable).

#### Atomicity

All transactions must be all-or-none, and partially-committed transactions are not allowed.

- Transaction aborts can be caused by users, the transaction itself, the operating system or the computer
- The recovery manager is responsible for recovery
- The DBMS logs all actions (both in memory and on disk) so that it can undo the actions of aborted transaction

#### Consistency

- A transaction should not break the consistency of the database.
  - Not only the integrity constraints
  - But also application-dependent consistency constraints
- Usually the user (writing SQL queries) is responsible for ensuring the consistency

#### Isolation

The database system must ensure that transactions operate properly without interfering with concurrently executing database statements

- For each transaction, it should be executed in a way as if it were the only transaction running.
  - This can be easily ensured by running transactions serially.
  - However, running multiple transactions concurrently has significant benefits
    - Improved throughput and resource utilization
    - Reduced average response time

##### Concurrency Control

DMBS achieves concurrency by interleaving the operations of transactions

- The **concurrency control manager** is responsible for
  - interleaving transactions
  - assuring the equivalence of interleaved operation and some serialized operations

#### Durability

A transaction's actions must persist across crashes

- The **recovery manager** is responsible for recovering commited transactions from possible failures.

## Transaction Isolation

- Interleaved operations may lead to unexpected execution results, depending on the order of execution
- Even if all transactions are executed serially, the order of execution may still affect the final result

### Benefits of Concurrency

- Improved throughput and resource utilization
- Reduced waiting time: concurrent execution reduces unpredictable delays and average response time

### Schedule

- A schedule specifies the chronological order in which instructions of transactions are executed

#### Serial Schedules

In a **serial schedule**, instructions belonging to a single transaction appear together in the schedule

- A *serial schedule* executes transactions sequentially
- For a schedule containing $n$ transactions, there are $n!$ valid serial schedules

#### Concurrent Schedules

- Interleaving allows maximizing concurrency, but may lead to results inconsistent with those of sequential execution if a bad interleaving schedule is applied
  - A good schedule requires that the effect must be equivalent to the transactions running serially *in some order*

#### Serializable Schedule

- A schedule is **serializable** if it is equivalent to some serial execution of the transactions
- If each transaction preserves consistency, then every serializable schedule perserves consistency

There are many types of serializabilities, depending on the exact definition of "equivalence to serial schedules"

$$ Serializable \subseteq ConflictSerializable \subseteq ViewSerializable $$

We will focus on conflict serializable schedules

##### Simplified View of Transactions

- A simplified schedule contains only **read** and **write** operations

##### Conflicting Operations

Consider two operations $I$ and $J$ in transactions $T_i$ and $T_j$.

- If $I$ and $J$ manipulate different data items, then $I$ and $J$ can be swapped without affecting the results of any instructions in the schedule.
- If $I$ and $J$ manipulates the same data item $Q$, then the order of the two steps may matter.

Two operations of two *different transactions* **conflict** if they 

1. access the same object and
2. at least one of them is a write

Conflicts do not always leads to problems, but they are indeed the source of problems.

###### Write-Read Conflict

- A transaction reads a value written by another transaction that has not yet committed
- Dirty Read. The order of $I$ and $J$ affects the result of the read.

###### Read-Write Conflict

- A transaction reads the value of the same object twice. Another transaction modifies the value between the two reads
- Unrepeatable Read. The order of $I$ and $J$ affects the result of the read.

###### Write-Write Conflict

- Two transactions write the same object, the second write overwriting the first change.
- The order of $I$ and $J$ affects any further read on the item, as well as the final value of the item.

#### Conflict Serializability

- Two schedules $S$ and $S'$ are **conflict equivalent** if they
  - involve the same actions of the same transactions
  - every pair of conflicting operations is ordered in the same way
  - i.e. if $S$ can be transformed to $S'$ by a series of swaps of non-conflicting operations
- A schedule $S$ is **conflict serializable** if it is conflict equivalent to some serial schedule
  - i.e. $S$ is conflict serializable if it can be transformed to a serial schedule by swaping non-conflicting operations of different transactions
  - It is possible that two schedules produce the same result, but are not conflict equivalent

##### Precedence Graph

Consider a schedule $S$ for transactions $T_1,\dots,T_n$. The precedence grpah $G$ of $S$ is defined as

- Each node of $G$ represents a transaction in $S$
- There exists an edge from $T_i$ to $T_j$ if
  - An operation $O_i$ of $T_i$ conflicts with an operation $O_j$ in $T_j$
  - $O_i$ appears earlier in $S$ than $O_j$
- Schedule $S$ is serialzable iff its precedence graph is acyclic
  - Can be checked with a DFS algorithm
- If the precedence graph is acyclic, then a *topological ordering* of the transactions procuces an equivalent serialized schedule

#### View Serializability

- Two schedules $S$ and $S'$ are **view equivalent** if
  - Every value read in $S$ equals to the one read by the same read in $S'$
    - i.e. a read operation in $S$ and $S'$ yields the same result
  - The final value of every object is written by the same $T$ in $S$ and $S'$
- A schedule $S$ is **view serializable** if $S$ is view equivalent to some serial $S'$

Every conflict serializable schedule is also view serialzable. But the converse may not hold.

- Testing for view serializability is NP-hard
  - All possible orderings must be considered
- Conflict serializability is often used in practice
  - Not because of the NP-hardness of view serializability
  - But because we have a way to enforce conflict serializability as transactions run

### Schedule Recovery

- A schedule $S$ is **recoverable** if whenever a transaction $T$ commits, all transactions who have written data read by $T$ have already commited.
  - That is, if $T_1$ writes something and $T_2$ reads it, if $T_1$ commits *after* $T_2$ does, then the schedule would be *non-recoverable*: if $T_1$ aborts after $T_2$ commits, $T_2$ should also be aborted, but this cannot be done because it has committed.

#### Cascading Rollbacks

Even if a schedule is recoverable, to correctly recover from its failure, serveral other transactions may have to also be aborted.

- Such situations occur if some other transactions have read values written by an aborted transaction $T_i$, before $T_i$ commits.

The phenomenon that a single transaction failure leads to a series of transaction rollbacks is called **cascading rollback**

- This is not desirable, as it leads to undoing a significant amout of work

##### Cascadeless Schedules

- A cascadeless schedule avoids cascading aborts/rollbacks.
  - Whenver a transaction $T$ reads a data item, any transaction $T'$ that has last written it must already have committed *before the read operation of $T$*.
- A cascadeless schedule enforces stronger constraint, and thus *a cascadeless schedule is always a recoverable schedule*.

## Lock-based Concurrency Control

### Lock: Recap

A transaction $T$ is allowed to access a data item only if $T$ holds a **lock** on that item

- **Shared Lock (S)**: If transaction $T$ holds a shared-mode lock on data $Q$, then $T$ can read but not write $Q$
  - Several transactions can hold the same lock because read operations will not lead to conflicts
- **Exclusive Lock (X)**: If transaction $T$ holds an exclusive-mode lock, then $T$ can both read and write the item
  - At most one transaction can hold an exclusive lock
  - Exclusive locks are not compatible with shared locks
    - a transaction cannot immediately acquire an exclusive lock on item $Q$, if another transaction is holding a shared lock on $Q$

!!!note Waiting for Locks
    To access a data item, the transaction must hold the lock on that item. The lock is only granted if all incompatible locks held by other transactions are released.

    Otherwise, the transaction has to wait until it acquires the lock (i.e. wait until all incompatible locks are released)

!!!info Releasing Locks
    *It is not always desirable to immediately release the lock after a transaction's final access to the item, because this may lead to inconsitencies in some schedules.*

    “在你放锁的时候，可能发生很多事情。”

### 2-Phase Lock (2PL) Protocol

Basic lock machenism is not enough because it does not guarantee conflict serializability. One protocol that ensures conflict serializability is the **two-phase locking protocol**

In the two-phase lock protocol, all lock requests preced all unlock requests.

1. Growing Phase
   - Transactions may obtain locks
   - Transactions may not release locks
2. Shrinking Phase
   - Transactions may release locks
   - Transactions may not obtain locks

> 2PL protocol guarantees conflict serializability

#### Lock Point

The **lock point** $t$ of a transaction $T$ is the point when $T$ successfully acquires all the lock it needs

#### Analysis of 2PL

Let $t_i$ be the lock point of $T_i$. A 2PL schedule is conflict equivalent to the serial schedule obtained by ordering the transactions w.r.t. their lock points.

**Lemma**: $t_i < t_j$ for every edge $(T_i, T_j)$ in the precedence graph.

- Note that once this lemma hold, it follows that the precedence graph is acyclic.

*Intuition*: Let $O_i$ and $O_j$ be a pair of conflicting operations that induce $(T_i, T_j)$. With 2PL, $T_j$ cannot acquire the lock for $O_j$ until $T_i$ releases it.

*Proof*: Let $t_a(O_i)$ be the time when $T_a$ obtains lock for $O_i$. Let $\bar{t}_a(O_i)$ be the time when $T_i$ releases the lock. Let $t_a, t_b$ be the lock point of $T_a, T_b$. By definition of 2PL, we have $t_a \in [t_a(O_i), \bar{t}_a(O_i)]$.

Further, $t_b(O_j) \in ( \bar{t}_a(O_i), t_b ]$ or otherwise the lock cannot be obtained.

Finally, we have $t_b \ge t_b(O_j) > t_a$

!!!note
    Note that 2PL protocol does not prevent dead locks. (Textbook page 840)

#### Lock Conversion

- During the growing phase
  - Transactions can acquire a shared or exclusive locks
  - Transactions are allowed to convert a shared lock to an exclusive lock (upgrade)
- During the shrinking phase
  - Transactions can release a shared or exclusive locks
  - Transactions are allowed to convert an exclusive lock to a shared lock (downgrade)

2PL with Conversion can improve concurrency, and it also ensures serializability

#### Implementation of Locks

Lock and unlock requests are handled by the lock manager. It maintains a **lock table**: a hash table over the lock entries, it maps locks to their entry queues.

##### Lock Table

- On a lock request, the transaction is added to the entry queue.
- On an unlock request, the first transaction in the queue is re-activated
- The lock table may also keep a list of locks held by each transaction
  - when a transaction aborts, the locks held by this transaction can be released efficiently

### Stricter 2PL Protocols

#### Strict Two-Phase Locking

A 2PL protocol is not enough for preventing cascading aborts, because transactions can still read uncommited data.

- The Strict 2PL Protocol requires that *exclusive locks can be released only after the transaction commits*.
  - Guarantees that transactions never read other transactions' uncommited data
  - Ensures *serializability*, *recoverability*, and *avoids cascading aborts*.

#### Rigorous Two-Phase Locking

- Rigorous 2PL requires that a transaction can release all locks only after it commits.
  - R/W operations can be issued interactively
  - Difficult to determine whether a transaction no longer needs a lock
- With rigorous 2PL, transactions can be serialized in the order in which they commit

### Deadlock Handling

#### Deadlock Recap

> "拿着锁等锁"

- A deadlock is a cycle of transactions waiting for locks to be released by each other.

##### Waits-for Graph

- Nodes are transactions
- An edge from $T_i$ to $T_j$ implies that $T_i$ is waiting for a lock currently held by $T_j$
- A deadlock occurs iff there exists a cycle in the waits-for graph

#### Deadlock Prevention

##### Simple Implementation

- Require a transaction to acquire all locks it needs before it starts execution
  - But it is often hard to predict what locks it requires
  - Data-item utilization can also be low
- Require a transaction lock items only in a specific ordering
  - e.g. once a transaction locks an item, it cannot lock any other items preceding this item in the ordering

##### Preemptive Deadlock Prevention

- Assign priorities based on timestamp
  - Older timestamps indicate higher priority

Suppose $T$ requests a lock currently held by $T'$

- **Wait-Die**: $T$ waits for $T'$ if $T$ has higher priority (earlier timestampe), and otherwise $T$ aborts. (Non-preemptive)
- **Wound-Wait**: $T'$ aborts if $T > T'$, and otherwise $T$ waits.

!!!note Notes on Deadlock Prevention
    - There is no cycles in the waits-for graph.
    - If a transaction re-starts, it inherits its previous priority and timestamp
      - In order to prevent starvation

#### Deadlock Detection

- Creates a waits-for graph
- Periodically checks for cycles in the graph

##### Recovery from Deadlock

- **Victim Selection**: Rollback the transaction that will incur minimum cost to break the cycle
  - *minimum cost* depends on factors including how long it has been executed, how much longer it needs before it completes, how many data items have been and will be used, how many transactions will be involved...
- **Rollback**: Determine how far to roll back the transaction
  - Total rollback: Abort the transaction and restarts it
  - Partial rollback: Rollback as far as necessary to release a lock that another transaction in the cycle is waiting for
- **Starvation**: A transaction can only be chosen as the victim for a limited number of times to prevent starvation, or to include the number of rollbacks into the cost factor

### Locking Granularity

- The lock can be placed on a tuple, a page, a table or the entire database
- Tradeoff between overhead and concurrency
  - Finer granularity: high concurrency, high locking overhead (both time and space cost)
  - Coarse granularity: low locking overhead, low concurrency
- The database hierarchy can be represented as a tree
  - When a transaction locks a node in the tree explicitly, all child nodes are also implicitly locked

#### Examples

- A transaction joins multiple relations in a database
  - Locks the entire database
- A transaction linearly scans a relation
  - Locks the relation
- A transaction accesses only part of a relation with a B+ tree index
  - Locks a small number of tuples

#### Intention Locks

An intention lock allows a higher level node to be locked in shared or exclusive mode without having to check all descendent nodes. (So some attempts to acquire a lock do not need to traverse the children)

If a node is locked in **intention mode**, it means that an explicit lock exists at lower level in this subtree. Intention locks are put on all ancestors of a node before the node is locked explicitly

- Intention-Shared (IS)
  - An explicit S lock exists in child nodes
- Intention-Exclusive (IX)
  - An explicit X or S lock exists in child nodes
- Shared and Intention-Exclusive (SIX / S + IX)
  - Subtree rooted at current node is locked in shared mode
  - Another explicit shared or exclusive lock exists at lower level
  - Can be used when linearly scanning the relation and update some tuples

##### Compatibility Matrix with Intention Locks Included

##### Examples

> Locks are acquired in a top-down manner

- Scans relation $R$ and updates a few tuples
  - An SIX lock on $R$, and X locks on the tuples that are updated
- Uses index to read part of $R$
  - An IS lock on $R$, and repeatedly gets an $S$ lock on some tuples of $R$
- Linearly scans $R$
  - An S lock on $R$

## Timestamp-Based Concurrency Control

### Timestamps

Each transaction $T$ receives a timestamp $TS(T)$ before it starts execution, given by the system's clock or a logical counter (increments after a new timestamp has been assigned)

Each data item $Q$ is associated with two timestamps

- $WTS(Q)$: the most recent TS of any transaction $T$ that **wrote** $Q$ successfully
- $RTS(Q)$: the most recent TS of any transaction $T$ that **read** $Q$ successfully

The timestamps are updated whenever a read or write operation on $Q$ is executed successfully

### Basic Timestamp-Ordering (T/O) Protocol

- The **timestamp order** defines a serializability order
  - If $TS(T) < TS(T')$, then the system must ensure that in an equivalent serial schedule, $T$ must appear before $T'$
  - The timestamp-ordering protocol ensures that any conflicting R/W operations are executed in the timestamp order
- For each $R(Q)$ and $W(Q)$ request issued by a transaction $T$, the scheduler checks **operation conflicts**
  - Once a conflict is detected, transaction $T$ is aborted and restarted with a new timestamp

#### Read Rule

Suppose $T$ issues $R(Q)$

- If $TS(T) < WTS(Q)$, this violates the timestamp order of $T$ w.r.t. some transaction $U$ that writes $Q$
  - i.e. a transaction $U$ with more recent timestamp has written $Q$ before $T$ reads it
  - $T$ is aborted and restarted
- Otherwise, $R(Q)$ is executed, and $RTS(Q)$ is updated by $\max(RTS(Q), T(S))$

#### Write Rule

Suppose $T$ issues $R(Q)$

- If $TS(T) < RTS(Q)$ or $TS(T) < WTS(Q)$
  - i.e. a transaction $U$ with more recent timestamp has either read or written $Q$
  - $T$ is aborted and restarted
- Otherwise, the write request is permitted and $WTS(Q)$ is updated by $TS(T)$

#### Serializability

This basic T/O protocol assures serializability, as conflicting operations are executed in the order of the timestamps. In the precedence graph, transactions with smaller timestamps points to those with more recent timestamps, so there will be no cycles.

- Deadlock free, since no transaction is actually waiting
  - Does not prevent starvation
- However, schedules may not be recoverable or cascadeless
  - Recoverability and cascadelessness can be ensured
    - by performing all writes together at the end of transaction, and during the writes, no transactions can access the items that have been written
    - by a limited form of locking: postpone read of uncommitted writes until the writes have committed (**commit bit**)

### Thomas' Write Rule

- The *read rules* are not changed
- The *write rules* are slightly modified
  - If $TS(T) < RTS(Q)$, then abort and restart $T$
  - If $TS(T) < WTS(Q)$, then ignore the write and continue
  - Otherwise, perform the write and update the timestamp of $Q$

!!!example
    Consider two transactions $T_1$ and $T_2$, with $TS(T_1) < TS(T_2)$. If $T_1$ attempts to write $Q$ after $T_2$ wrote $Q$, in the basic timestamp-ordering, $T_1$ will be rolled back because $TS(T_1) < WTS(Q)$.

    However, this is not necessary, since $T_1$ is writing a value that will never be read again: for any $T_i$ that attempts to read $Q$ with $TS(T_i) < TS(T_2)$, they will be rolled back; for any $T_i$ that attempts to read $Q$ with $TS(T_i) > TS(T_2)$, they will read the value written by $T_2$ (instead of $T_1$), and therefore the write operation of $T_1$ can be discarded

Thomas' Write Rule ignores some write operations and thus avoids some W-W conflicts.

- Does not guarantee conflict serializability
- However, it *guarantees view serializability*
  - The writes ignored by Thomas' Write Rule are *obsolete* writes that will never be read by other concurrent transactions

#### Basic T/O with Thomas' Write Rule

- $T$ issues $R(Q)$
  - The same as before
- $T$ issues $W(Q)$
  - If $TS(T) < RTS(Q)$ then rollback $T$
  - If $TS(T) < WTS(Q)$ then ignore $W(Q)$ and continue $T$
  - Else allow $W(Q)$

### Recoverability

Basic T/O Protocol (with or without Thomas' Write Rule) does not guarantee recoverability or cascadelessness

#### Ensuring Recoverability

Use an additional boolean $C(Q)$ to check *whether the latest transaction that writes $Q$ has committed*.

- Delay any request to read or write $Q$ if $C(Q)$ is false.

#### Revised T/O Protocol

- $R(Q)$
  - If $TS(T) < WTS(Q)$: Abort and restart $T$
  - $C(Q) = false$: Delay $T$
  - Otherwise allow $R(Q)$ of $T$ and update $RTS(Q)$
- $W(Q)$
  - If $TS(T) < RTS(Q)$: Abort and restart $T$
  - Else if $TS(T) < WTS(Q)$
    - If $C(Q) = false$: delay $T$
    - Else ignore $W(Q)$ and continue
  - Otherwise allow $W(Q)$ of $T$, update $WTS(Q)$, and set $C(Q)$ to $false$

### Recap

- Basic T/O Protocol
  - Ensures conflict serializability
- Basic T/O w/ Thomas' Write Rule
  - Ensures view serializability
  - Improves concurrency
- Revised T/O (w/ commit bit)
  - Avoids cascading aborts

## Validation-based Protocol

The validation-based protocol is also based on a timestamp mechanism. However, unlike previous T/O protocols that give each transaction a timestamp when then are started, the timestamp is assigned according to the time when $T$ enters validation (see below).

### Overview

Also known as **optimisitc concurrency control (OCC) protocol** because it assumes transactions would be able to finish execution and pass a validation

- Optimistic
- Process transaction as if they would succeed
- Check for serializability *only at commit time*
- If it fails, the transaction is aborted

Have high performance when there are few conflicts and locking

### Three Phases of OCC

1. Read Phase
   - $T$ executes and sorts its writes to temporary local variables
   - $T$ also tracks its **read set** $RS(T)$ and **write set** $WS(T)$
2. Validation Phase
   - A validation test is performed to check if $T$ can commit
   - i.e. whether the local update can be applied without violating serializability constraints
   - If $T$ fails the test, it will be rolled back
3. Write Phase
   - If $T$ passes validation, the update is then actually performed on the database

#### Read Set and Write Set

- **Read Set** $RS(T)$: The elements that $T$ reads
- **Write Set** $WS(T)$: The elements that $T$ writes

The line of text here is used to split the two unordered lists.

- Each transaction stores the updates to $WS(T)$ in a local storage in the Read Phase
  - Dirty results are isolated
  - Other transactions cannot see these updated values
- After the Read Phase, if $T$ passes the validation, then the updates are applied to the DB

#### Validation Phase

- Each transaction is assigned with a *timestamp* that determines the serial equivalent order
- The timestamp of $T$ is assigned according to the time when $T$ *finishes its read phase and enters its validation phase*

When a transaction $T_j$ completes its read phase, then for each $T_i$

- If $TS(T_i) < TS(T_j)$, then $T_j$ must satisfies at least one of the validation rules (see below)
- Otherwise $T_j$ is aborted
- If the transactions satisfies the validation, then serializability can be ensured

!!!note Lemma
    If $TS(T_i) < TS(T_j)$, then for any conflicting operations $O_i$ and $O_j$ such that $O_i \in T_i$ and $O_j \in T_j$, the OCC scheduler places $O_i$ before $O_j$

    The validation rules will make sure that all conflicts go in one way. Thus OCC guarantees conflict serializability.

##### Validation Rules

- $T_i$ completes all three phases before $T_j$ begins

```text
    ┌─────┬─────┬─────┐
Ti  │  R  │  V  │  W  │
    └─────┴─────┴─────┘

           
                        ┌─────┬─────┬─────┐
Tj                      │  R  │  V  │  W  │
                        └─────┴─────┴─────┘
```

- $T_i$ completes its *write phase* before $T_j$ begins its *write phase*, and $WS(T_i) \cap RS(T_j) = \emptyset$ (items written by $T_i$ will not be read by $T_j$)
  - No conflicts between $WS(T_i)$ and $RS(T_j)$ (Items read by $T_j$ will not be written by $T_i$). Possible conflicts include $(R_i,W_j)$ and $(W_i, W_j)$, but all conflicting operations $O_i$ must have happened before $O_j$, so the direction in the dependence graph is one-way

```text
    ┌─────┬─────┬─────┐
Ti  │  R  │  V  │  W  │
    └─────┴─────┴─────┘

              ┌─────┬─────┬─────┐
Tj            │  R  │  V  │  W  │
              └─────┴─────┴─────┘
```

- $T_i$ completes its *read phase* before $T_j$ completes its *read phase* ($TS(T_i) < TS(T_j)$) and $WS(T_i) \cap RS(T_j) = \emptyset$, and $WS(T_i) \cap WS(T_j) = \emptyset$.
  - Only possible conflict is $(R_i, W_j)$.

```text
    ┌─────┬─────┬─────┐
Ti  │  R  │  V  │  W  │
    └─────┴─────┴─────┘

        ┌─────┬─────┬─────┐
Tj      │  R  │  V  │  W  │
        └─────┴─────┴─────┘
```

In the last 2 cases, the additional requirements ensure that items read by $T_j$ is not affected by the operations of $T_i$ (i.e., $T_j$ reads values that are already committed)

!!!note
    The validation scheme automatically prevents cascading rollbacks, because the actual writes take place only after the transaction has committed.

    However, it may cause starvation of long transactions
