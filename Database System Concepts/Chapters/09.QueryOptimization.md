# Query Optimization

## Overview of Query Optimization

1. Generate logical plans using equivalence rules
2. Annotate logical plans to get physical plans
   - A physical plan defines exactly what algorithms to use for each operation
   - And how the execution of the operations is coordinated
3. Estimate the cost of the physical plans, and choose the cheapest plan

## Rule-Based Query Rewriting

### Query Rewriting

Two relational algebra expressions are **equivalent** if they generate the same set of tuples

### Equivalence Rules

#### Pushdown Selection

$$ \sigma_{\theta\land\theta_1\land\theta_2}(r \bowtie_{\theta'} s) = \sigma_{\theta_1}(r) \bowtie_{\theta\land\theta'} \sigma_{\theta_2}(s) $$

where

- $\theta_1$ is a predicate involving only attributes of $r$
- $\theta_2$ is a predicate involving only attributes of $s$
- $\theta$ and $\theta'$ are predicates involving attributes of both $r$ and $s$

By pushing down selections, the hash operation can be performed on smaller sets of tuples.

#### Pushdown Projection

$$ \Pi_{L}(\sigma_\theta(r)) = \Pi_{L}(\sigma_\theta(\Pi_{L\cup L'}(r))) $$

where

- $L'$ is the set of attributes referred by $\theta$ that are not in $L$

By pushing down projections, the selection can be performed on fewer attributes

#### Others

- Natural join is associative and communitative (except for attribute ordering)
  - $r \bowtie s = s \bowtie r$
  - $r \bowtie s \bowtie t= r \bowtie (s \bowtie t)$
- $ \Pi_{L_1} (\Pi_{L_2}(r)) = \Pi_{L_1}(r) $ if $L_1 \subseteq L_2$
- $\sigma_\theta(r\times s) = r \bowtie_\theta s$
  - Convert product to theta join
- Refer to the textbook for more rules

### Query Rewriting Using Equivalence Rules

1. Start with a logical plan
2. Push selections/projections down
   - **Pros:** Reduces the size of intermediate results
   - **Cons:** Can be expensive in some cases (e.g. cases where the join operation filters tuples better than the selection)
3. Join small relations first, and avoid products
   - **Pros:** Reduces the size of intermediate results
   - **Cons:** Size also depends on join selectivity
4. Convert the logical plan to a physical plan

## Cost-Based Query Optimization

### Cost Estimation

- Total cost of a plan is the sum of all estimated costs of the operators in the plan
- Cost of a certain operator is proportional to the size of its input
- Size of operator input can be estimated by the *selectivity* of the operator and the size of its children

### Statistics and Catalog

- The DBMS stores internal statistics about tables, attributes and indices in internal catalogs
- Catalogs are updated periodically
- Modern databases use many sophisticated statistics

### Selectivity

The **selectivity factor** of a predicate $\theta$ is the probability that a tuple in relation $r$ satisfies $\theta$

#### Selection with Equality Predicates

$$ \sigma_{A = v}(r) $$

- Assume *the values of attribute $A$ are uniformly distributed in $r$*. Then $ n_r / V(A,r) $ would be the number of records that will satisfy the selection
  - $ V(A,r) $: Number of distinct values that appear in $r$ for $A$
  - $ n_r $: Number of tuples in relation $r$
- Selectivity factor of $A = v$ is $1 / V (A,r)$

##### Conjunctions

$$ \sigma_{A=v \land B=u}(r) $$

- Further assumes $A = v$ and $B = u$ are *independent*
  - which may not hold
- Selectivity factor: $ 1 / (V(A,r) \cdot V(B,r))$

##### Negation

$$ \sigma_{A \neq v}(r) $$

- Selectivity factor: $1 - 1/V(A,r)$
- Generally, selectivity of $\neg\theta$ is $(1 - Selectivity(\theta))$

##### Disjunctions

$$ \sigma_{A=v\lor B=u}(r) $$

- $ 1 / V(A,r) + 1/V(B,r) - 1/ (V(A,r)V(B,r)) $

#### Range Predicates

Assume the max and min values of $A$ are available in the catalog

- Selectivity factor: $ (v - min(A,r)) / (max(A,r) - min(A,r)) $

### Size Estimation

Assume we want to estimate the size of $r(A,B) \bowtie s(A,C)$

- If $A$ is a key of $r$ (and a foreign key in $s$), then $|r \bowtie s| = n_s$
- Generally ($A$ is not a key for either table), the size is estimated by
  - Estimate the size of the product $r \times s = n_r n_s$
  - Take $\min( n_rn_s / V(A,r), n_rn_s / V(A,s) )$ as the estimation of the size

### Estimation Errors

- Skewness is one of the main reasons that may lead to poor estimations
- THe assumption of mutual independence of predicates may also not hold

#### Histograms

- We can build histograms in the catalog to better estimate common predicates
  - Equi-width: Equal range of bins
  - Equi-depth: Break up bins such that each bin has (approximately) the same number of tuples
- Many DBMS also store the $n$ most-frequent values and their counts (heavy hitters), and build histograms on remaining values
  - Exclude frequent items for a better histogram landscape

### Cost-Based Plan Search

- Enumerate possible physical plans
- Pick the plan with the least estimated cost
- The goal is often not getting the optimal plan, but instead avoiding horrible ones

> We will be focusing on join operators

#### Order of Join

- The search space of join ordering can be huge, making brutal-force enumeration impractical

##### Left-Deep Join

Early DBMS implementations used **left-deep join**: restricting that only the left-join of a join can be a join operator.

- Allows to generate fully pipelined plans in most cases
  - Intermediate results will not be written to temporary files
  - Some joins are not fully-pipelined (e.g. sort-merge join)
- $n!$ different left-deep join trees

##### Dynamic Programming and Selinger Algorithm

Let $\mathbb{X} \subseteq \{ r_1, \dots, r_n \}$ with $|\mathbb{X}| = k$,

$$ Opt(\mathbb{X}) = \min_{r\in\mathbb{X}} \{ Opt(\mathbb{X} - \{r\}) + Cost(\mathbb{X} - \{r\}, r) \} $$

- Cost
  - Time cost $n\cdot 2^n$
    - Can be slightly larger since we need to consider different join operators
  - Space cost $2^n$

##### Interesting Order

- The subplan of the optimal plan may not be optimal
  - The result of a sort-merge join is sorted on the join attribute
  - which can be exploited by later processing
- This can be dealt with by computing multiple optimal plans (one for each intereting order)
- Increases the complexity by a factor of $k+1$, where $k$ is the number of interesting orders
