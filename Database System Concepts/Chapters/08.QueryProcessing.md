# Query Processing

## Overview

1. Parsing and Translation
   - Check syntax and verify relations
   - Translate the query into its internal form and then translate it into relational algebra
2. Query Optimization
   - Each relational algebra can be evaluated with one of several different algorithms
   - Optimization constructs annotated expressions specifying detailed evaluation strategies, called **evaluation plans**
3. Evaluation

## Query Optimization

### Measures of Query Cost

- Many factors contribute to time costs
  - disk access
  - CPU
  - network
- Cost can be measured by
  - Response time
  - Resource consumption

> We use *total resource consumption* as cost metric. As the response time varies from machine to machine.
> More specifically, we only consider the **disk cost**

#### Disk Cost

The disk cost can be estimated by

- **#(seek)**: Number of disk seeks
- **#(pages)**: Number of page read/write

## Algorithms for RA Operations

- [Selection](#selection)
- [Sort](#sort)

### Selection

$$ \sigma_{attr=value}(R) $$

#### Linear Scan

- Scan each file block and test all records for the selection condition
- Can be applied regardless of
  - selection condition
  - ordering of records in the file
  - availability of indices
- `#(seeks) = 1`
- `#(pages) = N`
- General purpose, but slow

#### Index Scan with Clustering Index

##### Clustering B+ Tree with Equality on Key

> Retrieve a **single record** that satisfies the corresponding equality condition

- Let `h_i` be the height of the B+ Tree
  - `#(seek) = h_i + 1`
  - `#(page) = h_i + 1`

##### Clustering B+ Tree with Equality on Non-Key

> Retrieve multiple records

- Let `b` be the number of pages containing the search-key
  - `#(seek) = h_i + 1`
  - `#(page) = h_i + 1 + b`

#### Index Scan with Secondary Index

##### Equality on Key

- Retireve a single-record since the search-key is a candidate key
  - `#(seek) = h_1 + 1` `#(page) = h_i + 1`

##### Equality on Non-Key

- Retrieve multiple candidates
  - `#(seek) = h_i + n` `#(page) = h_i + n`
  - `n` is the number of matching tuples. Since each record may be on a different page

#### Selections Involving Comparisons

##### Clustering B+ Tree

- For $A \ge V$, use index to find first tuple $\ge V$ and scan sequentially
- For $A \le V$, scan from the beginning sequentially until first tuple $> V$. Does not require using index.
  - `#(seek) = h_i + 1` `#(page) = h_1 + 1 + b`
  - `b` is the number of pages where tuples satisfying the constraints are located

##### Non-Clustering B+ Tree

- Algorithm is basically the same
  - `#(seek) = h_i + n` `#(page) = h_i + n` because tuples may not locate on the subsequent pages
  - Requires an IO per record; Linear scan may be cheaper

#### Conjunction

$$ \sigma_{\theta_1 \wedge \cdots \wedge \theta_n}(R) $$

##### Using One Index

- Select $\theta_i$ s.t. the selection implementation results in the least cost for $\theta_i$ and test other conditions after fetching the tuples into memory buffer

##### Using Composite Index

- Use composite (multi-key) index if available

##### Intersection of Identifiers

- Require indices

### Sort

#### Sorting in DBMS

- Physical sorting
  - Sort tuples
- Loigcal sorting with indexing
  - Cheaper, but may lead to one IO per record in future queries

#### External Sorting

- If data fits in memory, then a standard sorting algorithm can be applied
- External sorting is used when
  - data do not fit in memory
  - IO-cost-aware

#### External Merge Sort

Takes a **divide-and-conquer** approach that first splits data into separate runs and then sort them individually

- **Sort Phase**: Sort blocks of data that fit in main-memory and then write back the sorted blocks to a sub-file on disk
- **Merge Phase**: Combine sorted sub-files into a single large file

##### Sorting Phase

Assume there are $M$ available pages in memory

1. Read $M$ pages of relations into memory
2. Sort the in-memory pages
3. Write each sorted data to a separate **run file**

##### Merging Phase

Merge runs separately

1. Use $M-1$ pages as input from sorted runs
2. The remaining 1 page is used as the output buffer
3. Merge each $m-1$ runs into a new run, stored on the buffer

##### Cost Analysis

Let `N` be the pages in the input table

- `# passes = 1 + K` where `K = ceil(log(N/M, M-1))`
  - One pass for the merge phase
  - `K` passes for the merge phase
- `# pages = (2K + 1) N`
  - Assumes it does not write sort output to disk
- `# seeks = 2 * ceil(N / M) + N * (2K - 1)`
  - Two seeks for each page in the merge phase
