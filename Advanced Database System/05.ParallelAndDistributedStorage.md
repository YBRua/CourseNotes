# Parallel and Distributed Storage

## Data Partition

**I/O parallelism** refers to reducing the time required to retrieve data from disk by partitioning the data over multiple disks.

- **Horizontal partitioning.** The tuples of a relation are partitioned among many nodes, where each tuple resides in one node.
- **Vertical partitioning.** The attributes of a relation are partitioned among nodes.
  - E.g., suitable for applications where some attributes are frequently used.

### Partitioning Strategies

- **Round-robin.** Ensures an even distribution of tuples across nodes.
- **Hash paritioning.**
  - Designates one or more attributes in a tuple as the partitioning attributes.
  - Compute hash on the partitioning attributes and place the tuple to nodes accordingly.
- **Range partitioning.** Distributes tuples by assigning contiguous attribute-value ranges to each node.
  - Select a paritioning attribute

#### Maintaining the Partition

- When a tuple is inserted, it is distributed to the appropriate node according to the partitioning strategy.
- When a tuple is removed, it is first found based on the partitioning attribute and then removed.
  - For round-robin, all nodes search for this node in parallel.
- When a node is updated and the partitioning attribute is updated
  - It will be removed from the original node and sent to a new node according to the updated value.
  - No need to change location if is round-robin or it does not update partitioning attribute.

#### Comparison of Partitioning Techniques

We consider three types of access to data items.

1. Scanning the entire relation.
2. Point queries. Seek tuples that have a specified value for a specific attribute.
3. Range queries. Locating all tuples for which the value of a given attribute lies within a specified range.

- **Round-robin.**
  - Suitable for scanning the entire relation. All nodes can execute in parallel, and the runtime does not vary too much.
  - Not suitable for point or ranged queries. All nodes need to be scanned.
- **Hash partitioning.**
  - Suitable for (1) point queries on partitioning attributes. (2) Scanning the entire relation.
  - Not suitable for point queries on other attributes or ranged queries.
- **Range Partitioning.**
  - Suitable for point or ranged queries on partitioning attributes.
  - **Execution skew.** If there are many tuples in the queried range, many tuples need to be retrieved from a few nodes, resulting in I/O bottlenecks.

!!!note ""
    Partitioning is worthwhile only if each node would contain a few disk blocks worth of data.

## Skew in Partitioning

**Data distribution skew.** An imbalance distribution of data, with a high percentage of tuples placed in some partitions and fewer tuples in other partitions.

- **Attribute-value skew.** Some values appear in the partitioning attributes in many tuples. Such tuples end up in the same partition.
- **Partition skew.** There may be load imbalance in the partitioning even if there is no attribute skew.

Even a small skew could result in a significant decrease in performance. Skew becomes an increasing problem with higher degree of parallelism.

#### Balanced Range-Partitioning Vectors

A balanced range-partitioning vector can be constructed by sorting

1. Sort the relation on the partitioning values.
2. Scan the relation in sorted order.
3. After every $1/n$ of the relation has been read, split the read data into a new partition.

- The main disadvantage is the extra I/O overhead incurred during the sort.
- Can be reduced by using a precomputed histogram.

#### Virtual Node Partitioning

Assume there are several times as many **virtual nodes** as the number of real nodes.

- Tuples are mapped to virtual nodes, by any partitioning schemes.
- Reduces skew.

#### Dynamic Repartitioning

## Replication

With a large number of nodes, the probability that at least a node would fail is significantly larger than in a single-node system.

- Parallel systems must be resilient to node failures.
  - The data should not be lost.
  - The entire system should continue to be available.
- Tuples are replicated along at least two nodes, and often three nodes

### Location of Replicas

- A single node fails due to internal errors.
- Nodes on a single rock fails.
- An entire data center fails.

## Parallel Indexing

- **Local index.** An index built on tuples stored in a particular node.
  - Stored on the same node as the data
- **Global index.** An index built on data stored across multiple nodes.
  - Contents of a global index are also partitioned across mulitple nodes

- **Global primary index.** A global index on the attributes on which the tuples of the relations are partitioned (i.e., a global index on a partitioning attribute).
- **Global secondary index.** A global index on non-partitioning attributes.
