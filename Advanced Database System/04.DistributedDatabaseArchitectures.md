# Database System Architectures

- **Centralized database system.** Run on a single physical machine that supports multitasking.
- **Parallel database system.** Execute tasks in parallel on a large number of machines.
- **Parallel data storage system.** Designed primarily to store and retrieve data based on keys.
  - Limited support for transactions.
  - Lack support for declarative querying.
- **Distributed database system.** Support executing and updating transactions across multiple databases.

## Centralized Database Systems

- Run on a single computer system.
- Two categories distinguished by ways the computer is used
  - **single-user system.** limited concurrent control and recovery capability.
    - a.k.a. **embedded system** because they are typically designed to be linked to a single program.
  - **multiuser system.** usually designed as **servers**.
- **Coarse-grained parallelism** refers to the parallelism with a small number of cores (e.g., on a PC) with shared memory.
  - Database systems designed for time-shared single-processor machines could be adapted relatively easily to support coarse-grained parallelism.
  - Because many issues for processes running truly in parallel have been addressed.
  - Databases running on coarsely-grained parallel machines traditionally do not attempt to partition a single query among multiple processors.
- In contrast, in a **fine-grained parallel** machine, a single query could be parallelized.

## Server System Architectures

Server systems could be classified as **transaction servers** and **data servers**.

- **Transaction-server system.** A.k.a. **query-server** systems. Provides an interface to which clients can send requests to perform an action (typically a transaction).
- **Data-server system.** Client interact with servers to read or update data (files, pages or objects).

### Transaction-server Systems

### Data-server Systems

## Parallel Systems

Parallel systems improve processing and I/O speeds by using a large number of computers in parallel.

- A **coarse-grain parallel** machine consists of a small number of powerful processors
- A **massively parallel** or **fine-grain parallel** machine uses thousands of smaller processors
- Each computer is referred to as a **node** in the system.
  - The computers have their own independent memory and disks.
- Parallel systems at the scale of hundreds to thousands of nodes or more are housed in a **data center**.

### Motivation for Parallel Databases

- The demands of applications that have to query extremely large databases.
- The demands of applications that have to process an extremely large number of transactions per second.
- Web-scale applications today require to handle the vast number of users from the web.
- The *set-oriented* nature of database queries naturally lends itself to parallelization.

### Measures of Performance for Parallel Databases

#### Main Measures

- **Throughput.** The number of tasks that can be completed in a given time interval.
  - For a system that processes a large number of small transactions: parallelism improves throughput.
- **Response time.** The amount of time it takes to complete a single task after it is submitted.
  - For a system that processes large transactions: parallelism improves response time.

#### Issues in Studying Parallelism

##### Speedup

Running a given task in less time by increasing the degree of parallelism.

- The speed up due to parallelism is defined as $T_S / T_L$.
  - $T_S$ and $T_L$ are execution times on a smaller / larger machine.
- **Linear speedup.** The speedup is $N$ when the larger system has $N$ times the resources of the smaller system.
- **Sublinear speedup.** The speedup is less than $N$.
- **Superlinear speedup.** The speedup is larger than $N$.

##### Scaleup

The ability to process larger tasks in the same amount of time by providing more resources.

- **Linear scaleup.**
- **Sublinear scaleup.**
- **Two kinds of scaleup** relevant in parallel databases.
  - **Batch scaleup.** The size of the database increases, and the tasks are jobs whose runtime depends on the size of the database.
  - **Transaction scaleup.** The rate at which transactions are submitted increases, and the size of the database increases proportionally to the transaction rate.

#### Factors that Work against Efficient Parallelism

- **Sequential computation.** Components in a task that have to be executed sequentially.
  - **Amadahl's Law.** Assume a task takes time $T$ to run sequentially. Suppose the total execution time that can benefit from parallelization is $p$, and is executed by $n$ nodes in parallel,
    - The total time taken would be $(1-p)T + (p/n)T$.
    - The speedup would be $1/((1-p) + (p/n))$
  - **Gustafson's Law.** The scaleup for the problem with $n$ times more resources and $n$ times larger scale would be $(1/(n(1-p) + p))$
- **Startup cost.** A startup cost related with initializing a new process.
- **Interference.** Processes competing for common resources.
- **Skew.** The service time for the single slowest step
will determine the service time for the task as a whole.

### Interconnection Networks

#### Tree-like Interconnection

- Tree topology with three layers. Frequently used in local area networks.
  - **core switch.** Connects to multiple aggregation switches, also connects to outside network
  - **aggregation switch.** Interconnects different ranks
- **top-of-rack switch.** A.k.a. **edge switches**. Provides interconnections between server nodes.

However, the tree topology could not provide sufficient bandwidth if multiple machines in a rach try to communicate large amounts of data with machines from other racks.

- Tree-like topology
  - Each top-of-rack switch connects to multiple aggregation switches
  - Each aggregation swith connects to multiple core switches.
- Increase bandwidth and tolerance for failures

### Parallel Database Architectures

#### Shared Memory

- All processors share a common memory, typically through an interconnected network.
- Extremely efficient communication between processes.
  - Messages can be sent much faster via a memory write than via other communication mechanisms.
- **Architectures.**
  - **Common bus.** Early implementations use buses.
    - The bus or the interconnection network becomes the bottleneck.
    - **Non-Uniform Memory Architecture (NUMA).**

#### Shared Disk

#### Shared Nothing

#### Hierarchical

## Distributed Systems

In a **distributed database system**, the database is stored on nodes located at *geographically separated* **sites**.

The nodes in a distributed system communicate with one another through various communication media (e.g., network). They do *not* share memory or disks.

!!!note Differences between shared-nothing parallel databases and distributed databases.
    - Distributed databases have sites that are *geographically separated*.
      - Network connections have lower bandwidth, higher latency and higher probability of failures.
      - In contrast, nodes in parallel systems are connected with high-speed communication media.
    - Distributed databases need to contiue working even if an entire data center fails.
      - In contrast parallel databases usually suffer great loss in such an event, despite tolerance to small failures (such as a single node).
    - Distributed databases may be separately administered, with each site retaining some degree of autonomy of operation.
    - Nodes in a distributed database tend to vary more in size and function.
      - Nodes in a parallel system tend to have similar capacity.
    - In distributed database systems, we differentiate two types of transactions
      - A **local transaction** is one that accesses data only from nodes where the transaction is created.
      - A **global transaction** is one that accesses data from one or more different nodes.

### Transaction Processing in Parallel and Distributed Systems

*Atomicity of transactions* is an important issue in parallel and distributed database systems.

E.g., a transaction cannot commit on one node but abort on another.

#### Two-Phase Commit Protocol

The **two-phase commit (2PC) protocol** is the most widely used transaction commit protocol to ensure atomicity.

#### Concurrency Control

Deadlock detection needs to be carried out across multiple nodes.
